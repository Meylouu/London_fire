{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Incidents -----------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Ajuster les paramètres pour afficher toutes les lignes et colonnes\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Chargement des 2 dataset\n",
    "df1 = pd.read_csv(\n",
    "    \"../data/LFB Incident data from 2009 - 2017.csv\", sep=\",\", low_memory=False\n",
    ")\n",
    "df2 = pd.read_csv(\n",
    "    \"../data/LFB Incident data from 2018 onwards.csv\", sep=\",\", low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaténation\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# suppression des \".00\" sur certaines lignes de \"IncidentNumber\"\n",
    "df[\"IncidentNumber\"] = df[\"IncidentNumber\"].apply(\n",
    "    lambda x: str(x)[0:-3] if (\".00\" in x) & (str(x)[-3:] == \".00\") else x\n",
    ")\n",
    "\n",
    "# formatage des dates\n",
    "df.DateOfCall = pd.to_datetime(df.DateOfCall, format=\"%d-%b-%y\")\n",
    "df.TimeOfCall = pd.to_datetime(df.TimeOfCall, format=\"%H:%M:%S\")\n",
    "\n",
    "# création de champs Mois et DayOfWeek\n",
    "df[\"Month\"] = df[\"DateOfCall\"].dt.month\n",
    "df[\"DayOfWeek\"] = df[\"DateOfCall\"].dt.dayofweek + 1\n",
    "\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestDoublonSousCatégorie(categorie, ssCategorie):\n",
    "    # Vérifie si les StopCodeDescription existe en double dans les IncidentGroup\n",
    "    result = df.groupby(ssCategorie)[categorie].nunique()\n",
    "    print(result[result.values > 1])\n",
    "    print(\"Na pour\", categorie, df[categorie].isna().sum())\n",
    "    print(\"Na pour\", ssCategorie, df[ssCategorie].isna().sum())\n",
    "\n",
    "TestDoublonSousCatégorie(\"IncidentGroup\", \"StopCodeDescription\")\n",
    "print(\"\\n\", \"6 na sur IncidentGroup et pas de doublon, peut supprimer la colonne IncidentGroup\")\n",
    "\n",
    "print()\n",
    "TestDoublonSousCatégorie(\"PropertyCategory\", \"PropertyType\")\n",
    "print(\"\\n\", \"6 na sur PropertyCategory et 6 pour PropertyType, peut supprimer la colonne PropertyCategory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge de SpecialService dans Stopcode\n",
    "StopCodeDescription\t\n",
    "\n",
    "SpecialServiceType\n",
    "\n",
    "drop SpecialServiceType \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des données inutiles, en doublon métier, ou non présente au moment de la prédiction\n",
    "df = df.drop(\n",
    "    [\n",
    "        \"DateOfCall\",\n",
    "        \"TimeOfCall\",\n",
    "        \"IncidentGroup\",\n",
    "        \"PropertyCategory\",\n",
    "        \"Postcode_full\",\n",
    "        \"UPRN\",\n",
    "        \"IncGeo_BoroughName\",\n",
    "        \"ProperCase\",\n",
    "        \"IncGeo_WardName\",\n",
    "        \"IncGeo_WardNameNew\",\n",
    "        \"Easting_m\",\n",
    "        \"Northing_m\",\n",
    "        \"Easting_rounded\",\n",
    "        \"Northing_rounded\",\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "        \"FRS\",\n",
    "        \"IncidentStationGround\",\n",
    "        \"FirstPumpArriving_AttendanceTime\",\n",
    "        \"SecondPumpArriving_AttendanceTime\",\n",
    "        \"SecondPumpArriving_DeployedFromStation\",\n",
    "        \"NumStationsWithPumpsAttending\",\n",
    "        \"PumpCount\",\n",
    "        \"PumpMinutesRounded\",\n",
    "        \"Notional Cost (£)\",\n",
    "        \"NumCalls\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde d'un fichier temporaire\n",
    "df.to_csv(\"../data/PreIncidents.csv\", sep=\";\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Mobilisations -----------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Ajuster les paramètres pour afficher toutes les lignes et colonnes\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Chargement des 3 dataset\n",
    "df1 = pd.read_csv(\n",
    "    \"../data/LFB Mobilisation data from January 2009 - 2014.csv\",\n",
    "    sep=\";\",\n",
    "    low_memory=False,\n",
    ")\n",
    "df2 = pd.read_csv(\n",
    "    \"../data/LFB Mobilisation data from 2015 - 2020.csv\", sep=\";\", low_memory=False\n",
    ")\n",
    "df3 = pd.read_csv(\n",
    "    \"../data/LFB Mobilisation data from 2021 - 2024.csv\",\n",
    "    sep=\",\",\n",
    "    low_memory=False,\n",
    "    usecols=lambda column: column not in [\"BoroughName\", \"WardName\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaténation\n",
    "df = pd.concat([df1, df2, df3], axis=0)\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# formatage des dates\n",
    "df.DateAndTimeMobilised = pd.to_datetime(df.DateAndTimeMobilised, format='%d/%m/%Y %H:%M')\n",
    "df.DateAndTimeMobile = pd.to_datetime(df.DateAndTimeMobile, format=\"%d/%m/%Y %H:%M\")\n",
    "df.DateAndTimeArrived = pd.to_datetime(df.DateAndTimeArrived, format=\"%d/%m/%Y %H:%M\")\n",
    "df.DateAndTimeLeft = pd.to_datetime(df.DateAndTimeLeft, format=\"%d/%m/%Y %H:%M\")\n",
    "df.DateAndTimeReturned = pd.to_datetime(df.DateAndTimeReturned, format=\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la colonne Temps sur site en seconde de la pompe par delta de temps arrivée et départ\n",
    "df[\"PumpOnSiteSeconds\"] = (df.DateAndTimeLeft - df.DateAndTimeArrived).dt.seconds\n",
    "display(df.head(3))\n",
    "\n",
    "# Regroupe les lignes par incidents, car il y a une ligne par incidents / camion avec un n° d'ordre\n",
    "# Comme on s'intéresse à prédire des temps, on calcule les temps par incidents, min, max et moyen\n",
    "# et on cherchera à prédire des tgemps\n",
    "# les infos de 1ere station sur place et nb de pompe seront prises à partir de incidents\n",
    "aggregated = (\n",
    "    df.groupby(\"IncidentNumber\")\n",
    "    .agg(\n",
    "        PumpSecondsOnSite_min=(\"PumpOnSiteSeconds\", \"min\"),\n",
    "        PumpSecondsOnSite_mean=(\"PumpOnSiteSeconds\", \"mean\"),\n",
    "        PumpSecondsOnSite_max=(\"PumpOnSiteSeconds\", \"max\"),\n",
    "        TurnoutTimeSeconds_min=(\"TurnoutTimeSeconds\", \"min\"),\n",
    "        TurnoutTimeSeconds_mean=(\"TurnoutTimeSeconds\", \"mean\"),\n",
    "        TurnoutTimeSeconds_max=(\"TurnoutTimeSeconds\", \"max\"),\n",
    "        TravelTimeSeconds_min=(\"TravelTimeSeconds\", \"min\"),\n",
    "        TravelTimeSeconds_mean=(\"TravelTimeSeconds\", \"mean\"),\n",
    "        TravelTimeSeconds_max=(\"TravelTimeSeconds\", \"max\"),\n",
    "    )    \n",
    "    .reset_index()\n",
    ")\n",
    "display(aggregated.head())\n",
    "\n",
    "# jointure de l'agrégat sur le dataframe pour ajouter les colonnes de temps\n",
    "merge = pd.merge(\n",
    "    df, aggregated, left_on=\"IncidentNumber\", right_on=\"IncidentNumber\", how=\"left\"\n",
    ").sort_values(by=[\"IncidentNumber\", \"PumpOrder\"])\n",
    "\n",
    "display(merge.head(10))\n",
    "print(merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pas de traitement particulier sur PlusCode_Code, car les lignes Add et RCA ne sont pas des lignes en doublons d'un Initial, et peuvent donc être traitées comme initial\n",
    "\n",
    "# suppression des duplicatas pour ne garder qu'une ligne par incidents\n",
    "merge = merge.drop_duplicates(subset=[\"IncidentNumber\"], keep=\"first\")\n",
    "merge.IncidentNumber.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des données inutiles, en doublon métier, ou non présente au moment de la prédiction\n",
    "merge = merge.drop(\n",
    "    [\n",
    "        \"CalYear\",\n",
    "        \"HourOfCall\",\n",
    "        \"ResourceMobilisationId\",\n",
    "        \"Resource_Code\",\n",
    "        \"PerformanceReporting\",\n",
    "        \"DateAndTimeMobilised\",\n",
    "        \"DateAndTimeMobile\",\n",
    "        \"DateAndTimeArrived\",\n",
    "        \"TurnoutTimeSeconds\",\n",
    "        \"TravelTimeSeconds\",\n",
    "        \"PumpOnSiteSeconds\",\n",
    "        \"AttendanceTimeSeconds\",\n",
    "        \"DateAndTimeLeft\",\n",
    "        \"DateAndTimeReturned\",\n",
    "        \"DeployedFromStation_Code\",\n",
    "        \"DeployedFromStation_Name\",\n",
    "        \"DeployedFromLocation\",\n",
    "        \"PumpOrder\",\n",
    "        \"PlusCode_Code\",\n",
    "        \"PlusCode_Description\",\n",
    "        \"DelayCodeId\",\n",
    "        \"DelayCode_Description\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde d'un fichier temporaire\n",
    "merge.to_csv(\"../data/PreMobilisations.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Merge Incidents et Mobilisations -----------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Ajuster les paramètres pour afficher toutes les lignes et colonnes\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Charge les dataset temporaire\n",
    "df_incidents = pd.read_csv(\n",
    "    \"../data/PreIncidents.csv\", sep=\";\", low_memory=False\n",
    ")\n",
    "df_mobilisations = pd.read_csv(\n",
    "    \"../data/PreMobilisations.csv\", sep=\";\", low_memory=False\n",
    ")\n",
    "\n",
    "display(df_incidents.head())\n",
    "display(df_incidents.info())\n",
    "\n",
    "display(df_mobilisations.head())\n",
    "display(df_mobilisations.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df = pd.merge(\n",
    "    df_incidents,\n",
    "    df_mobilisations,\n",
    "    left_on=\"IncidentNumber\",\n",
    "    right_on=\"IncidentNumber\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# on vérifie qu'il n'y a pas de doublon sur IncidentNumber avant de la supprimer\n",
    "print(\"IncidentNumber na :\", df.IncidentNumber.isna().sum())\n",
    "\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde d'un fichier temporaire\n",
    "df.to_csv(\"../data/PreProcessTemp.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage du fichier PreProcessTemp. Pas de doublon sur IncidentNumber, vérifié juste avant\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "df = pd.read_csv(\"../data/PreProcessTemp.csv\", sep=\";\", low_memory=False)\n",
    "\n",
    "display(df.head())\n",
    "display(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestion des NA\n",
    "\n",
    "def ShowNa():\n",
    "    # Affichage des NA\n",
    "    na_counts = df.isna().sum()\n",
    "    print(na_counts[na_counts > 0],\"\\n\")\n",
    "\n",
    "    print(\"SpecialServiceType est nullable, donc normal\")\n",
    "    df_temp = df.drop(\"SpecialServiceType\", axis=1)\n",
    "\n",
    "    print(\"\\ntotal ligne na\", df_temp.isna().any(axis=1).sum())\n",
    "    print(\"Total de lignes\", len(df))\n",
    "    print(\"Poucentage\", df_temp.isna().any(axis=1).sum() / len(df) * 100, \"%\")\n",
    "\n",
    "    print(\"\\nligne par année\")\n",
    "    # display(df.CalYear.value_counts())\n",
    "\n",
    "    # print(\"ligne na par année\")\n",
    "    # display(df_temp.loc[df_temp.isna().any(axis=1), \"CalYear\"].value_counts())\n",
    "    # print(\"Les lignes avec des na sont principalments des lignes d'avant 2014\")\n",
    "\n",
    "    # years = []\n",
    "    # for year in range(df_temp.CalYear.min(), df_temp.CalYear.max() + 1):\n",
    "    #     total = len(df_temp.loc[df_temp.CalYear == year])\n",
    "    #     na = df_temp[df_temp.CalYear == year].isna().any(axis=1).sum()\n",
    "    #     years.append([year, total, na, na / total * 100])\n",
    "\n",
    "    years = []\n",
    "    for year in range(df_temp.CalYear.min(), df_temp.CalYear.max() + 1):\n",
    "        for col in df_temp.columns:\n",
    "            total = len(df_temp.loc[df_temp.CalYear == year])\n",
    "            na = df_temp.loc[df_temp.CalYear == year, col].isna().sum()\n",
    "            if na > 0:\n",
    "                years.append([year, col, total, na, na / total * 100])\n",
    "\n",
    "    df_years = pd.DataFrame(years, columns=[\"Année\", \"Colonne\", \"Nb lignes\", \"Na\", \"%Na\"])\n",
    "    # display(df_years)\n",
    "    display(df_years.groupby([\"Année\", \"Colonne\"]).min())\n",
    "    display(df_temp.loc[df_temp.USRN.isna()].head(5))\n",
    "\n",
    "\n",
    "ShowNa()\n",
    "\n",
    "# supprime les lignes avec très peu de NA\n",
    "# les lignes avec des USRS vides datent d'avant 2015, on les supprime\n",
    "df = df.dropna(axis = 0, how = 'any', subset =[\"PropertyType\", \"AddressQualifier\", \"IncGeo_WardCode\", \"NumPumpsAttending\", \"USRN\"])\n",
    "ShowNa()\n",
    "\n",
    "# Il n'existe pas toujours de ligne d'intervention pour les lignes d'Incidents, on supprime les lignes sans informations de mobilisation, et parfois l'information est partiellement saisie\n",
    "df = df.dropna(axis=0, how=\"any\", subset=[\"PumpSecondsOnSite_min\", \"TurnoutTimeSeconds_min\", \"TravelTimeSeconds_min\", \"FirstPumpArriving_DeployedFromStation\"])\n",
    "ShowNa()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitmeent des catégories. Uniquement des catégories nominales\n",
    "# possibilité Test Anova,\n",
    "\n",
    "\n",
    "def ShowValues(col):\n",
    "    print(col, len(df[col].unique()))\n",
    "    # print(df[col].value_counts())\n",
    "\n",
    "cols_categ = [\n",
    "    \"StopCodeDescription\",\n",
    "    \"SpecialServiceType\",\n",
    "    \"PropertyType\",\n",
    "    \"AddressQualifier\",\n",
    "    \"Postcode_district\",\n",
    "    \"USRN\",\n",
    "    \"IncGeo_BoroughCode\",\n",
    "    \"IncGeo_WardCode\",\n",
    "    \"FirstPumpArriving_DeployedFromStation\",\n",
    "]\n",
    "\n",
    "# nb de valeurs par catégories\n",
    "for col in cols_categ:\n",
    "    ShowValues(col)\n",
    "\n",
    "cols_cible = [\n",
    "    \"PumpSecondsOnSite_min\",\n",
    "    \"PumpSecondsOnSite_mean\",\n",
    "    \"PumpSecondsOnSite_max\",\n",
    "    \"TurnoutTimeSeconds_min\",\n",
    "    \"TurnoutTimeSeconds_mean\",\n",
    "    \"TurnoutTimeSeconds_max\",\n",
    "    \"TravelTimeSeconds_min\",\n",
    "    \"TravelTimeSeconds_mean\",\n",
    "    \"TravelTimeSeconds_max\",\n",
    "]\n",
    "\n",
    "cols_cible_cat = [\"FirstPumpArriving_DeployedFromStation\", \"NumPumpsAttending\"]\n",
    "\n",
    "# prépare les X et y de tests\n",
    "X = df.drop(cols_cible, axis=1)\n",
    "list_y = []\n",
    "for col in cols_cible:\n",
    "    list_y.append([col, df[col]])\n",
    "\n",
    "df_temp = df[df.CalYear > 2020]\n",
    "\n",
    "# Sélection de caractéristiques récursive\n",
    "import statsmodels.api\n",
    "from statsmodels.api import stats \n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "cols_to_check = \"+\".join(cols_categ)\n",
    "for col in cols_cible:\n",
    "    print(\"Test de\", col)\n",
    "    result = smf.ols(f\"{col} ~ {cols_to_check}\", data=df_temp).fit()\n",
    "    table = stats.anova_lm(result)\n",
    "    display(table)\n",
    "    break\n",
    "\n",
    "# pour les temps de mobilisation on considère\n",
    "model = smf.ols(\n",
    "    formula=\"TravelTimeSeconds_min ~ StopCodeDescription + SpecialServiceType + PropertyType + USRN + HourOfCall\",\n",
    "    data=df_temp,\n",
    ")\n",
    "results = model.fit()\n",
    "# Résumé des résultats\n",
    "display(results.summary())\n",
    "\n",
    "model = smf.ols(\n",
    "    formula=\"PumpSecondsOnSite_min ~ StopCodeDescription + SpecialServiceType + PropertyType + USRN\",\n",
    "    data=df_temp,\n",
    ")\n",
    "results = model.fit()\n",
    "results_df = pd.DataFrame({\"coefficients\": results.params, \"pvalues\": results.pvalues})\n",
    "# Filtrer pour ne garder que les p-values <= 0.05\n",
    "significant_results = results_df[results_df[\"pvalues\"] <= 0.05]\n",
    "# Afficher les résultats filtrés\n",
    "display(significant_results)\n",
    "\n",
    "\n",
    "# StopCodeDescription 8\n",
    "# SpecialServiceType 22\n",
    "# PropertyType 291\n",
    "# AddressQualifier 11\n",
    "# Postcode_district 322\n",
    "# USRN 53339\n",
    "# IncGeo_BoroughCode 33\n",
    "# IncGeo_WardCode 843\n",
    "# FirstPumpArriving_DeployedFromStation 117\n",
    "\n",
    "# les cibles\n",
    "# concordance acec les cibles\n",
    "\n",
    "# PumpSecondsOnSite_min\n",
    "# PumpSecondsOnSite_mean\n",
    "# PumpSecondsOnSite_max\n",
    "# TurnoutTimeSeconds_min\n",
    "# TurnoutTimeSeconds_mean\n",
    "# TurnoutTimeSeconds_max\n",
    "# TravelTimeSeconds_min\n",
    "# TravelTimeSeconds_mean\n",
    "# TravelTimeSeconds_max\n",
    "# FirstPumpArriving_DeployedFromStation\n",
    "# NumPumpsAttending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprime IncidentNumber qui n'est plus nécessaire et ne doit pas être une donnée d'entrainement\n",
    "df = df.drop([\"IncidentNumber\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
