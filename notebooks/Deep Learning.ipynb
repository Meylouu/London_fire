{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Ajuster les paramètres pour afficher toutes les lignes et colonnes\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "#colonne cible type\n",
    "cols_cible_type = [\"TurnoutTimeSeconds\", \"TravelTimeSeconds\", \"PumpSecondsOnSite\"]\n",
    "#colonne Data par colonne cible type\n",
    "cols_Data = [\n",
    "    [\"CalYear\", \"HourOfCall\", \"Postcode_district\", \"Month\", \"DayOfWeek\"],\n",
    "    [\"CalYear\", \"HourOfCall\", \"Postcode_district\", \"Month\", \"DayOfWeek\"],\n",
    "    [\"CalYear\", \"PropertyType\", \"StopCode\"],\n",
    "]\n",
    "#colonne cible bins\n",
    "# utilise -1 sinon crée bizarrement des Nan pour les valeurs à 0 au lieu de mettre 0\n",
    "cols_cible_bins = [\n",
    "    {\n",
    "        \"bins\": np.array([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20000]) * 60,\n",
    "        \"labels\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 30],\n",
    "    },\n",
    "    {\n",
    "        \"bins\": np.array([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20000]) * 60,\n",
    "        \"labels\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 30],\n",
    "    },\n",
    "    {\n",
    "        \"bins\": np.array([-1, 5, 10, 15, 30, 45, 60, 120, 180, 360, 1000000]) * 60,\n",
    "        \"labels\": [5, 10, 15, 30, 45, 60, 120, 180, 360, 1000],\n",
    "    },\n",
    "]\n",
    "\n",
    "cols_cible_bins_numbers = [4, 10, 9]\n",
    "#colonne cible avec (min, mean, max) consideration\n",
    "cols_cible = [\n",
    "    [\"TurnoutTimeSeconds_min\", \"TurnoutTimeSeconds_mean\", \"TurnoutTimeSeconds_max\"],\n",
    "    [\"TravelTimeSeconds_min\", \"TravelTimeSeconds_mean\", \"TravelTimeSeconds_max\"],\n",
    "    [\"PumpSecondsOnSite_min\", \"PumpSecondsOnSite_mean\", \"PumpSecondsOnSite_max\"]\n",
    "]\n",
    "\n",
    "# copie profonde, sinon la simple copie fait une copie des références des sous tableaux, et leur changement modifie l'original\n",
    "cols_cible_minutes = copy.deepcopy(cols_cible)\n",
    "\n",
    "\n",
    "def load_df(col_cible_type):\n",
    "    \"\"\"\n",
    "    - Charge le dataset de la colonne cible type (_df_ready_{col_cible_type}.csv).\n",
    "    \n",
    "    Args:\n",
    "       col_cible_type : nom de la colonne cible type\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Le DataFrame contenant les données de la colonne cible type\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        f\"../data/_df_ready_{col_cible_type}.csv\", sep=\";\", low_memory=False\n",
    "    )\n",
    "    # Contrôle\n",
    "    # display(df.head(3))\n",
    "    # display(df.info())\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_df_full(col_cible_type):\n",
    "    \"\"\"\n",
    "    - Charge le dataset de la colonne cible type (_df_full_{col_cible_type}.csv).\n",
    "    \n",
    "    Args:\n",
    "       col_cible_type : nom de la colonne cible type\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Le DataFrame contenant les données de la colonne cible type\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        f\"../data/_df_ready_full_{col_cible_type}.csv\", sep=\";\", low_memory=False\n",
    "    )\n",
    "    # Contrôle\n",
    "    # display(df.head(3))\n",
    "    # display(df.info())\n",
    "    return df\n",
    "     \n",
    "def create_cols_cible_minutes(df, index, bins=-1):\n",
    "    \"\"\"\n",
    "    Crée de nouvelles colonnes cible basées sur des tranches en minutes pour une dataframe donnée.\n",
    "\n",
    "    Paramètres :\n",
    "    df (pandas.DataFrame) : La dataframe contenant les données.\n",
    "    index (int) : L'index correspondant au type de cible à transformer.\n",
    "    bins (int) : Le nombre de tranches (par défaut -1, utilise les valeurs prédéfinies).\n",
    "\n",
    "    Retourne :\n",
    "    pandas.DataFrame : La dataframe avec les nouvelles colonnes cible en minutes.\n",
    "    \"\"\"\n",
    "    # Crée 3 nouvelles target pour chaque min/mean/max, par tranche en minutes, pour la cible type actuelle\n",
    "    for index_cible, col_cible in enumerate(cols_cible[index]):\n",
    "        # bins = cols_cible_bins[index][\"bins\"]\n",
    "        # print(bins)\n",
    "        # labels = cols_cible_bins[index][\"labels\"]\n",
    "        # print(labels)\n",
    "\n",
    "        #Genere un nouveau nom pour chaque colonne cible en remplacant Seconds par Minutes\n",
    "        new_name = col_cible.replace(\"Seconds\", \"Minutes\")\n",
    "        print(new_name, col_cible)\n",
    "\n",
    "        #Determine le nombre de tranches(bins) \n",
    "        #soit par la valeur prédéfinies, soit par la valeur pasée en parametre\n",
    "        num_bins = cols_cible_bins_numbers[index] if bins == -1 else bins\n",
    "        new_bins = pd.qcut(df[col_cible], q=num_bins, precision=0)\n",
    "\n",
    "        # Prend la valeur haute de l'intervalle pour la nouvelle colonne\n",
    "        df[new_name] = new_bins.apply(lambda x: x.right) \n",
    "    \n",
    "        # 3. Affiche la répartition des observations dans chaque bin\n",
    "        # bin_counts = df[new_name].value_counts().sort_index()\n",
    "        # print(bin_counts)\n",
    "    \n",
    "        #Met à jour la liste des nouvelles colonnes cible en minute\n",
    "        cols_cible_minutes[index][index_cible] = new_name\n",
    "        print(\"cols_cible\", cols_cible)\n",
    "        print(\"cols_cible_minutes\", cols_cible_minutes)\n",
    "\n",
    "    #Affiche les premieres lignes du dataframe mise à jour\n",
    "    display(df.head(3))\n",
    "\n",
    "    #Retourne le dataframe mise à jour\n",
    "    return df\n",
    "\n",
    "def Create_X(df_limited, index):\n",
    "    \"\"\"\n",
    "    Crée un DataFrame X sans les colonnes cibles et ne conservant que certaines colonnes explicatives.\n",
    "\n",
    "    Paramètres :\n",
    "    df_limited (pandas.DataFrame) : La dataframe contenant les données initiales.\n",
    "    index (int) : L'index correspondant au type de données à utiliser.\n",
    "\n",
    "    Retourne :\n",
    "    pandas.DataFrame : La dataframe contenant uniquement les colonnes explicatives sélectionnées.\n",
    "    \"\"\"\n",
    "    #Affiche la dimension du dataframe initial\n",
    "    print(df_limited.shape)\n",
    "\n",
    "    # Crée X sans les variables cibles\n",
    "    # Crée une liste des colonnes à supprimer (cibles et NumPumpsAttending)\n",
    "    cols_to_remove = (\n",
    "        [item for sublist in cols_cible for item in sublist]\n",
    "        + cols_cible_minutes[index]\n",
    "        + [\"NumPumpsAttending\"]\n",
    "    )\n",
    "    print(\"cols_to_remove\", cols_to_remove)\n",
    "   # Supprime les colonnes spécifiées du dataframe \n",
    "    X = df_limited.drop(cols_to_remove, axis=1)\n",
    "\n",
    "    # Ne conserve que certaines colonnes explicatives\n",
    "    # Crée une liste des colonnes à conserver\n",
    "    cols_to_keep = [\n",
    "        col\n",
    "        for col in X.columns\n",
    "        if any(substring in col for substring in cols_Data[index])\n",
    "    ]\n",
    "    print(\"cols_to_keep\", cols_to_keep)\n",
    "    # Conserver uniquement ces colonnes spécifiées\n",
    "    X = X[cols_to_keep]\n",
    "    # Affiche les deux premières lignes du dataframe résultant\n",
    "    display(X.head(2))\n",
    "    # Affiche la dimension du dataframe résultant\n",
    "    print(X.shape)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def under_sampling(X_train, y_train):\n",
    "      \"\"\"\n",
    "    Réalise un suréchantillonnage des données d'entraînement en utilisant la méthode SMOTE.\n",
    "\n",
    "    Paramètres :\n",
    "    X_train (pandas.DataFrame) : Les caractéristiques d'entraînement.\n",
    "    y_train (pandas.Series) : Les étiquettes d'entraînement.\n",
    "\n",
    "    Retourne :\n",
    "    tuple : Un tuple contenant les caractéristiques et les étiquettes suréchantillonnées.\n",
    "    \"\"\"\n",
    "    # Réchantillonne\n",
    "    print(\"Resampling\")\n",
    "    print(len(X_train))\n",
    "    # Enregistre le temps de début\n",
    "    start_time = time.time()\n",
    "    print(y_train.value_counts())\n",
    "    # sampling = RandomUnderSampler(sampling_strategy=\"auto\", random_state=42)\n",
    "    \n",
    "    # Crée l'objet SMOTE pour le suréchantillonnage\n",
    "    print(\"Smote\")\n",
    "    sampling = SMOTE(random_state=42)\n",
    "    X_train_samp, y_train_samp = sampling.fit_resample(X_train, y_train)\n",
    "    # Affiche la répartition initiale des étiquettes\n",
    "    print(y_train_samp.value_counts())\n",
    "\n",
    "    # print(\"EditedNearestNeighbours\")\n",
    "    # sampling = EditedNearestNeighbours(n_jobs=-1)\n",
    "    # X_train_samp, y_train_samp = sampling.fit_resample(X_train_samp, y_train_samp)\n",
    "    \n",
    "    # print(\"ClusterCentroids\")\n",
    "    # sampling = ClusterCentroids(random_state=42)\n",
    "    # X_train_samp, y_train_samp = sampling.fit_resample(X_train, y_train) # 35 minutes sur 3 cibles\n",
    "\n",
    "\n",
    "    # print(\"RandomUnderSampler à 60%\")\n",
    "    # # Compte la taille initiale des classes avant SMOTE\n",
    "    # class_counts_before_smote = Counter(y_train)\n",
    "    # max_class_count_before_smote = max(class_counts_before_smote.values())\n",
    "    # # Calcule 60% de la taille de la classe majoritaire initiale pour chaque classe pour appliquer le RandomUnderSampler\n",
    "    # sampling_strategy = {label: int(0.60 * max_class_count_before_smote) for label in class_counts_before_smote}\n",
    "    # # Appliquer RandomUnderSampler pour ajuster les classes \n",
    "    # undersampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    # X_train_samp, y_train_samp = undersampler.fit_resample(X_train_samp, y_train_samp)\n",
    "    \n",
    "    # Enregistre le temps de fin\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Affiche la nouvelle répartition des étiquettes après suréchantillonnage\n",
    "    print(y_train_samp.value_counts())\n",
    "    \n",
    "    # Affiche la durée du suréchantillonnage\n",
    "    print(f\"Durée de SMOTE : {end_time - start_time:.2f} secondes\")\n",
    "    print(len(X_train_samp))\n",
    "    \n",
    "    # Retourne les données suréchantillonnées\n",
    "    return X_train_samp, y_train_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilisé : cuda\n",
      "-----------------------------------------------------\n",
      "year 2022\n",
      "-----------------------------------------------------\n",
      "(342634, 42)\n",
      "cols_to_remove ['TurnoutTimeSeconds_min', 'TurnoutTimeSeconds_mean', 'TurnoutTimeSeconds_max', 'TravelTimeSeconds_min', 'TravelTimeSeconds_mean', 'TravelTimeSeconds_max', 'PumpSecondsOnSite_min', 'PumpSecondsOnSite_mean', 'PumpSecondsOnSite_max', 'TurnoutTimeSeconds_min', 'TurnoutTimeSeconds_mean', 'TurnoutTimeSeconds_max', 'NumPumpsAttending']\n",
      "cols_to_keep ['CalYear', 'HourOfCall_0', 'HourOfCall_1', 'HourOfCall_2', 'HourOfCall_3', 'HourOfCall_4', 'Postcode_district_0', 'Postcode_district_1', 'Postcode_district_2', 'Postcode_district_3', 'Postcode_district_4', 'Month_0', 'Month_1', 'Month_2', 'Month_3', 'DayOfWeek_0', 'DayOfWeek_1', 'DayOfWeek_2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalYear</th>\n",
       "      <th>HourOfCall_0</th>\n",
       "      <th>HourOfCall_1</th>\n",
       "      <th>HourOfCall_2</th>\n",
       "      <th>HourOfCall_3</th>\n",
       "      <th>HourOfCall_4</th>\n",
       "      <th>Postcode_district_0</th>\n",
       "      <th>Postcode_district_1</th>\n",
       "      <th>Postcode_district_2</th>\n",
       "      <th>Postcode_district_3</th>\n",
       "      <th>Postcode_district_4</th>\n",
       "      <th>Month_0</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>DayOfWeek_0</th>\n",
       "      <th>DayOfWeek_1</th>\n",
       "      <th>DayOfWeek_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1248893</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248894</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CalYear  HourOfCall_0  HourOfCall_1  HourOfCall_2  HourOfCall_3  \\\n",
       "1248893       14             0             0             0             0   \n",
       "1248894       14             0             0             0             0   \n",
       "\n",
       "         HourOfCall_4  Postcode_district_0  Postcode_district_1  \\\n",
       "1248893             1                    0                    0   \n",
       "1248894             1                    0                    0   \n",
       "\n",
       "         Postcode_district_2  Postcode_district_3  Postcode_district_4  \\\n",
       "1248893                    0                    0                    1   \n",
       "1248894                    0                    0                    1   \n",
       "\n",
       "         Month_0  Month_1  Month_2  Month_3  DayOfWeek_0  DayOfWeek_1  \\\n",
       "1248893        0        0        0        1            0            1   \n",
       "1248894        0        0        0        1            0            1   \n",
       "\n",
       "         DayOfWeek_2  \n",
       "1248893            1  \n",
       "1248894            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342634, 18)\n",
      "--------------------------------------------------------------------------------\n",
      "/////////////////////////// cible TurnoutTimeSeconds_mean\n",
      "[tensor([[14,  1,  0,  ...,  1,  1,  0],\n",
      "        [16,  0,  0,  ...,  0,  1,  1],\n",
      "        [14,  1,  0,  ...,  1,  1,  0],\n",
      "        ...,\n",
      "        [15,  0,  0,  ...,  0,  1,  1],\n",
      "        [15,  0,  1,  ...,  0,  1,  1],\n",
      "        [14,  0,  0,  ...,  0,  1,  1]]), tensor([ 53.0000,  77.0000,  56.0000,  40.0000, 333.0000,  28.5000,  76.0000,\n",
      "         90.0000,  57.0000,  10.0000, 135.0000, 121.0000,  45.0000,  44.0000,\n",
      "        111.0000,  63.0000,  71.0000,  29.0000,  77.0000,  50.5000,  26.0000,\n",
      "        133.5000,  65.0000,   9.0000,  60.0000,  88.0000,  72.0000,  63.0000,\n",
      "         68.0000,  55.0000,  71.0000, 128.0000, 121.0000,  85.0000,  62.0000,\n",
      "         99.0000,  67.0000,  32.0000,  39.0000,  17.0000, 145.0000,  83.0000,\n",
      "         64.0000, 118.0000,  77.0000,  59.0000,  64.0000,  46.5000,  65.0000,\n",
      "        143.0000, 111.0000,  50.0000,  63.5000,  69.0000,  84.5000,  43.5000,\n",
      "         44.5000,  74.0000,  64.0000,  57.0000,  36.0000,  78.0000,  83.0000,\n",
      "         81.0000, 151.0000, 101.0000,  35.0000,  34.0000,  64.0000,  97.0000,\n",
      "         43.0000,  90.5000, 101.0000,  57.0000,  27.0000,  43.0000,  49.0000,\n",
      "        303.0000,  46.0000,  44.0000,  51.0000, 130.0000, 106.0000,  59.0000,\n",
      "        111.0000,  77.0000,  18.0000,  92.0000,  62.5000,  53.5000,  88.0000,\n",
      "        127.5000,  87.0000,  30.0000,  18.0000,   1.0000,  12.0000,  63.0000,\n",
      "         96.0000,  91.0000,  61.5000,  28.0000,  40.5000,  69.0000,  73.5000,\n",
      "         82.0000,  54.5000,  47.0000,  19.0000,  73.0000,  97.5000,  77.0000,\n",
      "         58.0000, 114.0000,  15.5000,  97.0000,  84.5000,  59.0000,  79.0000,\n",
      "         20.0000,  74.5000, 107.0000,  58.0000,  87.0000,  92.5000, 104.5000,\n",
      "         77.0000,  76.0000,  60.0000,  62.0000,  80.0000,  73.5000,  83.0000,\n",
      "         64.0000, 101.0000,  90.0000,  71.0000,  78.0000,  70.0000, 118.5000,\n",
      "         54.0000,  89.0000,  57.0000, 105.0000,  81.0000,  48.0000, 107.5000,\n",
      "         88.0000,  68.0000, 106.0000, 117.0000,  67.0000, 102.0000,  55.0000,\n",
      "         56.0000,  31.0000,  75.0000,  66.0000,  76.0000,  93.0000,  54.0000,\n",
      "        127.0000,  58.0000,  85.0000,  50.0000, 103.0000,  48.5000,  72.0000,\n",
      "         33.0000, 101.0000,  80.0000, 123.0000,  68.0000, 103.0000,  47.0000,\n",
      "         54.0000,  71.0000, 112.0000,  97.0000,  15.0000,  71.0000, 111.5000,\n",
      "         87.5000,  44.0000,   5.0000,  38.0000,  61.0000,  81.0000,  84.0000,\n",
      "         23.0000, 126.0000,  94.0000,  48.0000,  58.0000,  56.0000,  76.0000,\n",
      "         82.0000,  73.0000, 103.0000,  55.0000, 106.0000,  64.5000,  51.0000,\n",
      "        157.0000, 108.0000,  66.0000,  15.0000,  70.0000,  79.0000,  65.0000,\n",
      "          9.0000,  32.0000,  26.0000,  65.5000,  84.5000,  46.0000,  61.5000,\n",
      "         63.0000,  79.0000, 122.0000, 114.0000,  74.0000,  41.0000,  87.0000,\n",
      "        129.0000,  44.0000,  55.0000,  98.0000, 119.0000,  72.0000, 115.0000,\n",
      "         11.0000, 113.5000,  87.0000,  37.0000,  71.0000,  70.0000, 121.0000,\n",
      "         70.0000,  80.0000, 103.0000,  61.0000,  52.0000,  59.0000,  90.0000,\n",
      "         67.5000,  29.0000,  23.5000,  90.0000,  89.0000,  62.0000,  46.0000,\n",
      "         12.0000,  45.0000, 107.0000,  82.5000,  73.5000,  81.0000, 102.5000,\n",
      "         70.0000,  77.0000,  75.0000,  34.5000,  31.5000,  50.0000,  71.0000,\n",
      "        112.0000,  35.0000,  75.0000,  88.0000, 122.5000,  72.0000,  65.0000,\n",
      "         93.0000,  75.0000,  64.0000,  58.0000,  69.0000,  42.0000,  73.0000,\n",
      "         63.5000, 110.0000,  99.0000,  73.0000,  53.0000,  78.5000,  30.0000,\n",
      "         93.0000,  83.5000, 105.0000,  78.0000,  80.0000,  34.0000,  73.0000,\n",
      "         61.0000, 139.0000, 112.0000,  84.0000,  44.0000,  32.0000,  67.0000,\n",
      "         66.0000, 108.0000,  89.0000,  47.0000,  39.0000,  49.0000,  44.0000,\n",
      "         69.5000,  69.0000,  79.0000,  99.0000, 120.0000,  94.0000,  57.0000,\n",
      "         52.0000,  35.5000,  72.0000,  91.0000,  73.5000,  88.0000,  60.5000,\n",
      "         64.0000, 122.0000,  25.0000,  30.0000,  75.0000,  73.0000, 105.0000,\n",
      "          9.0000,  79.0000,  53.5000,  69.0000,  76.0000,  63.0000,  75.0000,\n",
      "         21.0000,  34.0000,  88.0000,  42.0000,  54.0000,  45.0000,  49.0000,\n",
      "         82.0000,  52.0000, 429.5000,  87.0000,   2.0000,  75.0000,  44.5000,\n",
      "        103.0000,  65.0000,  73.5000,  73.5000,  93.0000,  92.0000,  92.0000,\n",
      "         77.0000,  75.0000, 112.0000,  49.0000,  51.0000, 157.0000,  95.5000,\n",
      "          3.0000,  50.0000,  65.5000, 115.0000,  47.0000,  45.0000,  60.0000,\n",
      "        127.0000,  76.0000,  97.0000,  55.0000,  60.0000,  98.0000,  50.0000,\n",
      "         20.0000,  69.0000,  47.0000,  42.0000,  54.0000,  25.5000,  50.5000,\n",
      "         53.0000, 132.0000,  55.0000,  21.0000,  37.5000,  72.0000,  58.5000,\n",
      "         90.0000,  33.0000,  61.5000,  83.0000,  67.0000,  66.0000,  51.0000,\n",
      "         99.0000,  95.0000,  10.0000,  13.0000,  94.0000,  95.0000, 101.0000,\n",
      "        113.0000,  57.0000, 137.0000,  10.0000,  68.5000, 109.0000,  32.0000,\n",
      "         59.0000, 116.0000,  36.0000,  72.0000, 125.0000,  58.0000, 109.0000,\n",
      "         15.0000,  34.0000,  62.0000,  38.5000,  57.0000,  48.0000,  93.0000,\n",
      "         97.0000,  48.0000,  78.5000,  50.0000,  74.0000,  94.0000,  60.0000,\n",
      "         27.0000,  61.0000, 136.0000,  72.0000,  32.0000,  39.0000,  23.0000,\n",
      "         68.0000,  89.0000,  75.0000,  64.0000,  55.0000,   2.0000,  49.5000,\n",
      "         96.5000,  44.5000,  75.0000,  63.0000,  60.0000,  71.0000,  66.0000,\n",
      "         64.0000, 102.0000, 110.0000,  64.0000,  48.0000,  81.0000,  63.5000,\n",
      "         79.0000,  95.0000,  54.5000,  73.0000,  78.0000,  32.0000,  62.5000,\n",
      "        125.0000,  13.0000,  96.5000,  81.0000,  59.0000,  50.0000,  77.0000,\n",
      "         88.0000,  45.0000,  71.5000,  22.0000,  52.0000, 101.5000, 108.0000,\n",
      "         56.0000,  12.0000,  55.0000,  44.0000,  85.0000, 137.5000,  72.0000,\n",
      "         96.0000,  80.0000,  70.0000,  41.5000,  52.0000,  80.0000,  49.0000,\n",
      "         40.0000, 103.0000,  77.0000,  90.0000,  67.0000,  62.5000,  80.0000,\n",
      "         61.0000,  12.0000,  79.5000,  63.0000,  89.0000, 106.0000,  65.0000,\n",
      "        112.0000], dtype=torch.float64)]\n",
      "[tensor([[14,  0,  1,  ...,  0,  0,  1],\n",
      "        [16,  0,  1,  ...,  1,  1,  0],\n",
      "        [15,  1,  0,  ...,  0,  1,  1],\n",
      "        ...,\n",
      "        [16,  1,  0,  ...,  0,  0,  1],\n",
      "        [15,  0,  0,  ...,  1,  1,  0],\n",
      "        [15,  0,  0,  ...,  1,  0,  0]]), tensor([ 43.0000, 115.0000,  63.0000, 137.0000,  24.0000,  63.0000,  86.5000,\n",
      "        105.0000,  66.0000,  89.0000,  80.5000,  97.0000,  50.0000,  73.0000,\n",
      "         65.0000, 259.0000,  80.0000, 108.0000,  60.0000,  12.0000,  39.0000,\n",
      "         59.0000,  65.0000, 114.0000,  96.0000,  27.0000,  56.0000,  42.5000,\n",
      "         74.0000,  70.0000, 102.0000,  88.0000,  62.0000,  52.0000, 110.5000,\n",
      "         38.0000, 103.0000,  45.0000,  83.5000,  82.0000,  52.0000,  52.0000,\n",
      "         55.0000,  67.0000,  83.0000,  42.0000,  32.0000,  60.0000,  33.0000,\n",
      "         19.0000,  48.0000,  65.0000,  71.0000,  63.5000,  21.0000, 105.0000,\n",
      "         91.5000,  53.5000, 105.0000,  63.5000,  77.0000,  39.0000,  83.0000,\n",
      "         51.0000,  34.0000,  59.0000,  99.0000, 106.0000,  59.0000,  61.0000,\n",
      "         54.0000, 118.5000,  61.0000,  93.0000,  87.0000,  67.0000,  68.0000,\n",
      "         93.0000,  58.0000,  83.0000,  72.0000,  34.0000,  65.5000,  92.0000,\n",
      "         88.0000,  46.0000, 115.0000, 104.0000,  74.0000,  38.0000, 110.0000,\n",
      "        164.5000,  77.0000,  61.0000,  94.0000, 119.0000,  48.0000,  71.0000,\n",
      "         51.0000,  10.0000, 158.5000,  64.0000,  53.5000,  58.5000,  90.0000,\n",
      "        123.5000,  65.0000,  25.0000,  53.5000,  36.5000, 366.0000,  70.0000,\n",
      "         48.0000,  75.0000,  61.0000,  40.0000,  59.0000, 292.0000,  45.0000,\n",
      "         65.0000,  93.0000,  80.0000,  45.0000,  74.0000,  82.0000,  85.0000,\n",
      "         40.5000,  62.5000,  89.0000, 127.0000,  67.0000,  88.0000,  88.0000,\n",
      "        130.0000,  57.0000,  26.0000,  68.0000,  90.0000,  59.0000,  89.5000,\n",
      "        118.0000, 107.0000,  77.0000, 150.0000,  82.0000,  69.0000,  50.0000,\n",
      "        184.0000,  74.0000,  69.0000, 107.0000,  70.0000,  31.0000, 109.0000,\n",
      "        103.0000,  96.0000,  83.0000,  75.0000,  87.0000, 100.0000,  72.0000,\n",
      "         60.0000, 108.0000,  91.0000,  51.5000,  12.0000,  92.0000,  96.0000,\n",
      "         86.5000,  79.0000,  68.0000,  80.0000,  68.0000,  48.0000, 109.0000,\n",
      "         55.0000,  59.0000,  79.5000,  84.0000,  76.0000,  33.0000, 105.5000,\n",
      "         83.0000,  81.0000,  79.0000,  58.0000,   4.0000,  99.0000, 105.5000,\n",
      "         51.0000, 172.0000,  47.0000,  88.0000,  77.5000,  99.0000,  46.5000,\n",
      "        107.0000, 106.0000,  93.0000, 106.0000,  60.0000,  76.0000,  87.0000,\n",
      "         82.0000,  69.0000,  23.0000,  82.0000, 122.5000,  79.5000,  64.0000,\n",
      "         46.5000,  75.0000,  31.5000,  60.0000,  21.0000,  33.0000,  62.0000,\n",
      "         68.0000,  14.0000,  84.0000,  42.0000, 152.0000,  91.0000,  74.5000,\n",
      "         79.5000,  81.0000, 113.0000, 103.0000,  61.5000, 129.0000,  98.0000,\n",
      "         83.0000,  50.0000,  66.5000, 110.0000,  42.0000,  46.0000,  28.5000,\n",
      "         36.0000,  51.0000,  24.0000,  80.0000,  67.0000,  23.5000,  54.0000,\n",
      "         74.0000,  82.5000,  82.5000,  37.0000,  44.0000,  70.0000,  48.0000,\n",
      "         50.0000,  59.0000, 160.0000, 129.0000], dtype=torch.float64)]\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 100]           1,900\n",
      "              ReLU-2                  [-1, 100]               0\n",
      "            Linear-3                  [-1, 100]          10,100\n",
      "              ReLU-4                  [-1, 100]               0\n",
      "            Linear-5                  [-1, 100]          10,100\n",
      "              ReLU-6                  [-1, 100]               0\n",
      "            Linear-7                   [-1, 50]           5,050\n",
      "              ReLU-8                   [-1, 50]               0\n",
      "            Linear-9                    [-1, 1]              51\n",
      "================================================================\n",
      "Total params: 27,201\n",
      "Trainable params: 27,201\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 0.11\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 536/536 [00:07<00:00, 74.71it/s]\n",
      "Epoch 2/100: 100%|██████████| 536/536 [00:07<00:00, 69.76it/s]\n",
      "Epoch 3/100: 100%|██████████| 536/536 [00:08<00:00, 66.69it/s]\n",
      "Epoch 4/100: 100%|██████████| 536/536 [00:07<00:00, 74.49it/s]\n",
      "Epoch 5/100: 100%|██████████| 536/536 [00:07<00:00, 73.69it/s]\n",
      "Epoch 6/100: 100%|██████████| 536/536 [00:07<00:00, 68.33it/s]\n",
      "Epoch 7/100: 100%|██████████| 536/536 [00:07<00:00, 73.24it/s]\n",
      "Epoch 8/100: 100%|██████████| 536/536 [00:07<00:00, 67.50it/s]\n",
      "Epoch 9/100: 100%|██████████| 536/536 [00:08<00:00, 66.06it/s]\n",
      "Epoch 10/100: 100%|██████████| 536/536 [00:07<00:00, 72.65it/s]\n",
      "Epoch 11/100: 100%|██████████| 536/536 [00:07<00:00, 73.89it/s]\n",
      "Epoch 12/100: 100%|██████████| 536/536 [00:07<00:00, 72.67it/s]\n",
      "Epoch 13/100: 100%|██████████| 536/536 [00:07<00:00, 71.16it/s]\n",
      "Epoch 14/100: 100%|██████████| 536/536 [00:08<00:00, 64.45it/s]\n",
      "Epoch 15/100: 100%|██████████| 536/536 [00:08<00:00, 66.56it/s]\n",
      "Epoch 16/100: 100%|██████████| 536/536 [00:08<00:00, 65.40it/s]\n",
      "Epoch 17/100: 100%|██████████| 536/536 [00:07<00:00, 73.42it/s]\n",
      "Epoch 18/100: 100%|██████████| 536/536 [00:08<00:00, 65.46it/s]\n",
      "Epoch 19/100: 100%|██████████| 536/536 [00:07<00:00, 67.00it/s]\n",
      "Epoch 20/100: 100%|██████████| 536/536 [00:08<00:00, 64.90it/s]\n",
      "Epoch 21/100: 100%|██████████| 536/536 [00:10<00:00, 52.35it/s]\n",
      "Epoch 22/100: 100%|██████████| 536/536 [00:07<00:00, 73.12it/s]\n",
      "Epoch 23/100: 100%|██████████| 536/536 [00:06<00:00, 76.57it/s]\n",
      "Epoch 24/100: 100%|██████████| 536/536 [00:07<00:00, 74.38it/s]\n",
      "Epoch 25/100: 100%|██████████| 536/536 [00:07<00:00, 74.05it/s]\n",
      "Epoch 26/100: 100%|██████████| 536/536 [00:07<00:00, 74.99it/s]\n",
      "Epoch 27/100: 100%|██████████| 536/536 [00:07<00:00, 73.37it/s]\n",
      "Epoch 28/100: 100%|██████████| 536/536 [00:07<00:00, 75.85it/s]\n",
      "Epoch 29/100: 100%|██████████| 536/536 [00:07<00:00, 70.82it/s]\n",
      "Epoch 30/100: 100%|██████████| 536/536 [00:07<00:00, 73.02it/s]\n",
      "Epoch 31/100: 100%|██████████| 536/536 [00:07<00:00, 72.76it/s]\n",
      "Epoch 32/100: 100%|██████████| 536/536 [00:07<00:00, 75.56it/s]\n",
      "Epoch 33/100: 100%|██████████| 536/536 [00:07<00:00, 72.62it/s]\n",
      "Epoch 34/100: 100%|██████████| 536/536 [00:07<00:00, 74.62it/s]\n",
      "Epoch 35/100: 100%|██████████| 536/536 [00:07<00:00, 72.54it/s]\n",
      "Epoch 36/100: 100%|██████████| 536/536 [00:07<00:00, 75.24it/s]\n",
      "Epoch 37/100: 100%|██████████| 536/536 [00:07<00:00, 74.73it/s]\n",
      "Epoch 38/100: 100%|██████████| 536/536 [00:07<00:00, 72.14it/s]\n",
      "Epoch 39/100: 100%|██████████| 536/536 [00:07<00:00, 75.45it/s]\n",
      "Epoch 40/100: 100%|██████████| 536/536 [00:07<00:00, 72.36it/s]\n",
      "Epoch 41/100: 100%|██████████| 536/536 [00:07<00:00, 74.13it/s]\n",
      "Epoch 42/100: 100%|██████████| 536/536 [00:07<00:00, 71.22it/s]\n",
      "Epoch 43/100: 100%|██████████| 536/536 [00:07<00:00, 73.85it/s]\n",
      "Epoch 44/100: 100%|██████████| 536/536 [00:07<00:00, 71.42it/s]\n",
      "Epoch 45/100: 100%|██████████| 536/536 [00:07<00:00, 74.37it/s]\n",
      "Epoch 46/100: 100%|██████████| 536/536 [00:07<00:00, 70.89it/s]\n",
      "Epoch 47/100: 100%|██████████| 536/536 [00:07<00:00, 74.16it/s]\n",
      "Epoch 48/100: 100%|██████████| 536/536 [00:07<00:00, 73.18it/s]\n",
      "Epoch 49/100: 100%|██████████| 536/536 [00:07<00:00, 72.24it/s]\n",
      "Epoch 50/100: 100%|██████████| 536/536 [00:07<00:00, 73.10it/s]\n",
      "Epoch 51/100: 100%|██████████| 536/536 [00:07<00:00, 70.56it/s]\n",
      "Epoch 52/100: 100%|██████████| 536/536 [00:07<00:00, 73.83it/s]\n",
      "Epoch 53/100: 100%|██████████| 536/536 [00:07<00:00, 71.38it/s]\n",
      "Epoch 54/100: 100%|██████████| 536/536 [00:06<00:00, 76.75it/s]\n",
      "Epoch 55/100: 100%|██████████| 536/536 [00:07<00:00, 70.26it/s]\n",
      "Epoch 56/100: 100%|██████████| 536/536 [00:07<00:00, 72.80it/s]\n",
      "Epoch 57/100: 100%|██████████| 536/536 [00:07<00:00, 69.22it/s]\n",
      "Epoch 58/100: 100%|██████████| 536/536 [00:07<00:00, 72.76it/s]\n",
      "Epoch 59/100: 100%|██████████| 536/536 [00:07<00:00, 67.81it/s]\n",
      "Epoch 60/100: 100%|██████████| 536/536 [00:07<00:00, 71.98it/s]\n",
      "Epoch 61/100: 100%|██████████| 536/536 [00:07<00:00, 69.61it/s]\n",
      "Epoch 62/100: 100%|██████████| 536/536 [00:07<00:00, 69.57it/s]\n",
      "Epoch 63/100: 100%|██████████| 536/536 [00:07<00:00, 70.09it/s]\n",
      "Epoch 64/100: 100%|██████████| 536/536 [00:07<00:00, 70.39it/s]\n",
      "Epoch 65/100: 100%|██████████| 536/536 [00:07<00:00, 70.77it/s]\n",
      "Epoch 66/100: 100%|██████████| 536/536 [00:07<00:00, 70.07it/s]\n",
      "Epoch 67/100: 100%|██████████| 536/536 [00:07<00:00, 70.07it/s]\n",
      "Epoch 68/100: 100%|██████████| 536/536 [00:07<00:00, 68.80it/s]\n",
      "Epoch 69/100: 100%|██████████| 536/536 [00:07<00:00, 70.69it/s]\n",
      "Epoch 70/100: 100%|██████████| 536/536 [00:07<00:00, 68.89it/s]\n",
      "Epoch 71/100: 100%|██████████| 536/536 [00:07<00:00, 71.16it/s]\n",
      "Epoch 72/100: 100%|██████████| 536/536 [00:07<00:00, 70.48it/s]\n",
      "Epoch 73/100: 100%|██████████| 536/536 [00:07<00:00, 69.76it/s]\n",
      "Epoch 74/100: 100%|██████████| 536/536 [00:07<00:00, 69.13it/s]\n",
      "Epoch 75/100: 100%|██████████| 536/536 [00:07<00:00, 69.64it/s]\n",
      "Epoch 76/100: 100%|██████████| 536/536 [00:07<00:00, 69.18it/s]\n",
      "Epoch 77/100: 100%|██████████| 536/536 [00:07<00:00, 69.76it/s]\n",
      "Epoch 78/100: 100%|██████████| 536/536 [00:07<00:00, 70.33it/s]\n",
      "Epoch 79/100: 100%|██████████| 536/536 [00:07<00:00, 69.55it/s]\n",
      "Epoch 80/100: 100%|██████████| 536/536 [00:07<00:00, 69.38it/s]\n",
      "Epoch 81/100: 100%|██████████| 536/536 [00:07<00:00, 70.01it/s]\n",
      "Epoch 82/100: 100%|██████████| 536/536 [00:07<00:00, 68.32it/s]\n",
      "Epoch 83/100: 100%|██████████| 536/536 [00:07<00:00, 69.93it/s]\n",
      "Epoch 84/100: 100%|██████████| 536/536 [00:07<00:00, 67.53it/s]\n",
      "Epoch 85/100: 100%|██████████| 536/536 [00:07<00:00, 69.84it/s]\n",
      "Epoch 86/100: 100%|██████████| 536/536 [00:07<00:00, 68.62it/s]\n",
      "Epoch 87/100: 100%|██████████| 536/536 [00:07<00:00, 71.71it/s]\n",
      "Epoch 88/100: 100%|██████████| 536/536 [00:07<00:00, 68.83it/s]\n",
      "Epoch 89/100: 100%|██████████| 536/536 [00:07<00:00, 70.07it/s]\n",
      "Epoch 90/100: 100%|██████████| 536/536 [00:07<00:00, 67.53it/s]\n",
      "Epoch 91/100: 100%|██████████| 536/536 [00:07<00:00, 70.37it/s]\n",
      "Epoch 92/100: 100%|██████████| 536/536 [00:07<00:00, 68.09it/s]\n",
      "Epoch 93/100: 100%|██████████| 536/536 [00:07<00:00, 70.81it/s]\n",
      "Epoch 94/100: 100%|██████████| 536/536 [00:07<00:00, 69.16it/s]\n",
      "Epoch 95/100: 100%|██████████| 536/536 [00:07<00:00, 70.52it/s]\n",
      "Epoch 96/100: 100%|██████████| 536/536 [00:07<00:00, 70.67it/s]\n",
      "Epoch 97/100: 100%|██████████| 536/536 [00:07<00:00, 69.82it/s]\n",
      "Epoch 98/100: 100%|██████████| 536/536 [00:07<00:00, 70.32it/s]\n",
      "Epoch 99/100: 100%|██████████| 536/536 [00:07<00:00, 68.90it/s]\n",
      "Epoch 100/100: 100%|██████████| 536/536 [00:07<00:00, 70.13it/s]\n",
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100/100 -- Training loss 11703206.333955225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([187])) that is different to the input size (torch.Size([187, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([175])) that is different to the input size (torch.Size([175, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1598.6247834162925\n",
      "RMSE train : 34.18922020415068\n",
      "RMSE test : 34.473754602898055\n",
      "MAE train : 22.002475214264933\n",
      "MAE test : 22.068980878012514\n",
      "-----------------------------------------------------\n",
      "year 2022\n",
      "-----------------------------------------------------\n",
      "(342634, 45)\n",
      "cols_to_remove ['TurnoutTimeSeconds_min', 'TurnoutTimeSeconds_mean', 'TurnoutTimeSeconds_max', 'TravelTimeSeconds_min', 'TravelTimeSeconds_mean', 'TravelTimeSeconds_max', 'PumpSecondsOnSite_min', 'PumpSecondsOnSite_mean', 'PumpSecondsOnSite_max', 'TravelTimeSeconds_min', 'TravelTimeSeconds_mean', 'TravelTimeSeconds_max', 'NumPumpsAttending']\n",
      "cols_to_keep ['CalYear', 'HourOfCall_0', 'HourOfCall_1', 'HourOfCall_2', 'HourOfCall_3', 'HourOfCall_4', 'Postcode_district_0', 'Postcode_district_1', 'Postcode_district_2', 'Postcode_district_3', 'Postcode_district_4', 'Postcode_district_5', 'Postcode_district_6', 'Postcode_district_7', 'Postcode_district_8', 'Month_0', 'Month_1', 'Month_2', 'Month_3', 'DayOfWeek_0', 'DayOfWeek_1', 'DayOfWeek_2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalYear</th>\n",
       "      <th>HourOfCall_0</th>\n",
       "      <th>HourOfCall_1</th>\n",
       "      <th>HourOfCall_2</th>\n",
       "      <th>HourOfCall_3</th>\n",
       "      <th>HourOfCall_4</th>\n",
       "      <th>Postcode_district_0</th>\n",
       "      <th>Postcode_district_1</th>\n",
       "      <th>Postcode_district_2</th>\n",
       "      <th>Postcode_district_3</th>\n",
       "      <th>Postcode_district_4</th>\n",
       "      <th>Postcode_district_5</th>\n",
       "      <th>Postcode_district_6</th>\n",
       "      <th>Postcode_district_7</th>\n",
       "      <th>Postcode_district_8</th>\n",
       "      <th>Month_0</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>DayOfWeek_0</th>\n",
       "      <th>DayOfWeek_1</th>\n",
       "      <th>DayOfWeek_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1248893</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248894</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CalYear  HourOfCall_0  HourOfCall_1  HourOfCall_2  HourOfCall_3  \\\n",
       "1248893       14             0             0             0             0   \n",
       "1248894       14             0             0             0             0   \n",
       "\n",
       "         HourOfCall_4  Postcode_district_0  Postcode_district_1  \\\n",
       "1248893             1                    0                    1   \n",
       "1248894             1                    0                    1   \n",
       "\n",
       "         Postcode_district_2  Postcode_district_3  Postcode_district_4  \\\n",
       "1248893                    0                    0                    0   \n",
       "1248894                    0                    0                    0   \n",
       "\n",
       "         Postcode_district_5  Postcode_district_6  Postcode_district_7  \\\n",
       "1248893                    0                    0                    0   \n",
       "1248894                    1                    1                    0   \n",
       "\n",
       "         Postcode_district_8  Month_0  Month_1  Month_2  Month_3  DayOfWeek_0  \\\n",
       "1248893                    0        0        0        0        1            0   \n",
       "1248894                    0        0        0        0        1            0   \n",
       "\n",
       "         DayOfWeek_1  DayOfWeek_2  \n",
       "1248893            1            1  \n",
       "1248894            1            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342634, 22)\n",
      "--------------------------------------------------------------------------------\n",
      "/////////////////////////// cible TravelTimeSeconds_mean\n",
      "[tensor([[16,  1,  0,  ...,  0,  0,  1],\n",
      "        [16,  1,  0,  ...,  0,  1,  1],\n",
      "        [15,  1,  0,  ...,  0,  1,  1],\n",
      "        ...,\n",
      "        [16,  0,  0,  ...,  1,  0,  1],\n",
      "        [14,  0,  1,  ...,  1,  1,  1],\n",
      "        [14,  0,  1,  ...,  1,  1,  1]]), tensor([ 184.5000,  391.0000,  438.5000,  251.0000,  268.0000,  363.0000,\n",
      "         493.5000,  315.0000,  354.5000,  401.0000,  216.5000,  203.0000,\n",
      "         339.0000,  149.0000,  274.0000,  216.0000,  292.0000,  203.0000,\n",
      "         487.0000,  363.0000,  264.0000,  385.0000,   28.0000,  191.0000,\n",
      "         232.0000,  571.0000,  271.0000,   52.0000,  391.0000,  472.0000,\n",
      "          99.0000,  225.0000,  290.5000,  128.0000,  138.0000,   46.5000,\n",
      "         186.0000,  215.0000,  299.0000,  214.0000,  125.0000,  115.0000,\n",
      "         220.0000,  245.0000,  246.0000,  283.0000,  325.0000,  105.0000,\n",
      "         222.0000,  517.0000,  350.0000,  506.0000,  164.0000,  134.0000,\n",
      "         139.0000,  477.0000,  343.0000,  277.5000,   61.5000,  168.0000,\n",
      "         281.5000,  373.0000,  266.0000,  132.0000,  118.5000,  125.0000,\n",
      "         147.0000,  435.0000,  177.0000,  249.0000,  225.0000,  464.0000,\n",
      "         399.5000,  297.0000, 1076.0000,  314.0000,  174.0000,  192.0000,\n",
      "         242.0000,  331.0000,  130.0000,  665.0000,  354.0000,  157.0000,\n",
      "          71.0000,  354.0000,    4.0000,  193.0000,  231.5000,  146.0000,\n",
      "         257.0000,  405.0000,   94.5000,  262.5000,  194.0000,  333.0000,\n",
      "          93.0000,  172.0000,  188.0000,  424.0000,  391.0000,  369.0000,\n",
      "         237.5000,  457.0000,   86.0000,  428.0000,  376.0000,  414.0000,\n",
      "         329.5000,  189.0000,  331.0000,  383.5000,  537.0000,  312.0000,\n",
      "          49.0000,  223.0000,  305.0000,  152.0000,  814.0000,  175.0000,\n",
      "         238.5000,  190.0000,  681.0000,  262.5000,  305.0000,  282.0000,\n",
      "         365.5000,  373.0000,  102.0000,  192.0000,  152.0000,  320.0000,\n",
      "         323.5000,  323.5000,  231.0000,  167.0000,  606.0000,  237.0000,\n",
      "         484.0000,  407.5000,  235.5000,  165.0000,  130.0000,  407.0000,\n",
      "         258.0000,  283.5000,  206.0000,  346.0000,  234.0000,  374.0000,\n",
      "         352.0000,  232.0000,   93.0000,  255.5000,   88.5000,  297.0000,\n",
      "         159.0000,  213.0000,  400.0000,  192.0000,  228.0000,  261.5000,\n",
      "           3.0000,  272.0000,  351.0000,  106.0000,  167.0000,   85.5000,\n",
      "         289.5000,  196.0000,  449.0000,  295.0000,  113.0000,   65.0000,\n",
      "         197.0000,  199.5000,  141.0000,  164.0000,  394.0000,  235.0000,\n",
      "         181.0000,  169.0000,  302.0000,  299.5000,  302.0000,  291.0000,\n",
      "         192.0000,  234.5000,  225.0000,  302.5000,  291.0000,  281.5000,\n",
      "         111.0000,  406.0000,   16.0000,  225.0000,  324.5000,  221.0000,\n",
      "         222.0000,  371.0000,  106.0000,  172.5000,  290.0000,   89.0000,\n",
      "         263.0000,  131.0000,  264.0000,  216.0000,  148.0000,  375.0000,\n",
      "         238.0000,  209.0000,  437.0000,  300.0000,  542.0000,  356.5000,\n",
      "         192.0000,  121.0000,  277.5000,  238.0000,  141.0000,  275.0000,\n",
      "         210.0000,  230.0000,  270.0000,  140.0000,  323.0000,  353.0000,\n",
      "         254.0000,    4.0000,  259.0000,  369.0000,   95.0000,  218.0000,\n",
      "         125.0000,  274.5000,  278.0000,  201.0000,  337.0000,  288.0000,\n",
      "         176.0000,  264.0000,  306.0000,   15.0000,  388.0000,  258.5000,\n",
      "         166.0000,  190.5000,  436.0000,  225.0000,   86.0000,  335.0000,\n",
      "         367.0000,  176.0000,  352.5000,  262.0000,  145.0000,  210.0000,\n",
      "         330.0000,  228.0000,  167.0000,  234.0000,  228.5000,  162.0000,\n",
      "         262.0000,  221.0000,  246.0000,  226.0000,  346.0000,  341.0000,\n",
      "         280.0000,  124.0000,  232.0000,  327.5000,  152.0000,  755.0000,\n",
      "         162.0000,  265.0000,  330.0000,  579.0000,  351.5000,  332.0000,\n",
      "         374.0000,  237.0000,  253.0000,  264.0000,  240.0000,  135.0000,\n",
      "         572.0000,  426.0000,  151.0000,  279.0000,  425.0000,   78.5000,\n",
      "         279.0000,  125.0000,  284.0000,  517.0000,  339.0000,  169.0000,\n",
      "          83.0000,  178.0000,  183.0000,  210.0000,    0.0000,  123.0000,\n",
      "         172.5000,  344.0000,  336.5000,  222.0000,  176.0000,   96.0000,\n",
      "         317.0000,  425.0000,  309.0000,  247.5000,  337.0000,  362.0000,\n",
      "         257.0000,  114.0000,  257.0000,  290.5000,  179.0000,   83.0000,\n",
      "         204.5000,  371.0000,  211.0000,  163.0000,  210.0000,  310.0000,\n",
      "         222.0000,  218.0000,  234.0000,  223.5000,   99.0000,  249.0000,\n",
      "         274.0000,  356.0000,  298.5000,  258.0000,  330.0000,  204.0000,\n",
      "         185.0000,  171.0000,  134.5000,  646.0000,  242.0000,  250.0000,\n",
      "         299.0000,  286.0000,  296.5000,  458.0000,  194.0000,  463.0000,\n",
      "         145.0000,  305.0000,  136.0000,  136.0000,  162.0000,  320.0000,\n",
      "         154.0000,  152.0000,  310.0000,  143.0000,  540.0000,  165.0000,\n",
      "         294.0000,   67.0000,  392.0000,  196.0000,  468.0000,  226.0000,\n",
      "         336.0000,  159.0000,  194.0000,  383.0000,  249.0000,  443.5000,\n",
      "         161.0000,  216.0000,  316.0000,  174.0000,   68.0000,   81.5000,\n",
      "         147.0000,  203.0000,  212.5000,  414.5000,  350.5000,  340.5000,\n",
      "         254.0000,  499.0000,  197.0000,  436.0000,  405.0000,  256.0000,\n",
      "         201.0000,  237.0000,  342.5000,  299.0000,  142.0000,  180.0000,\n",
      "         418.0000,  189.0000,  167.0000,  104.0000,  453.0000,  248.0000,\n",
      "         246.0000,  205.0000,  293.0000,  434.5000,  175.0000,  282.0000,\n",
      "         103.0000,  360.0000,  433.0000,  377.5000,  125.5000,  484.0000,\n",
      "         213.0000,  163.0000,  245.0000,  392.0000,  196.0000,  399.0000,\n",
      "         368.0000,  518.0000,  165.0000,  186.0000,  129.0000,  252.0000,\n",
      "         330.0000,  516.0000,  271.5000,  297.0000,  293.5000,  125.0000,\n",
      "         265.0000,  509.5000,  162.0000,  425.0000,  232.0000,  219.0000,\n",
      "         227.0000,  259.0000,  257.5000,  194.0000,  204.0000,  291.0000,\n",
      "         312.0000,  846.0000,  373.0000,  192.0000,  243.0000,  777.0000,\n",
      "         226.0000,  340.0000,  403.0000,  198.0000,  240.0000,  254.0000,\n",
      "         165.0000,  265.0000,  222.0000,  160.0000,  199.0000,  287.0000,\n",
      "         699.5000,  138.0000,  325.0000,  123.0000,  471.0000,  272.0000,\n",
      "         413.0000,  505.0000,  289.0000,  330.0000,  166.0000,  227.0000,\n",
      "         360.0000,  250.0000,  370.5000,  598.0000,  159.0000,  306.0000,\n",
      "         382.0000,  463.0000,  496.0000,  227.0000,  187.0000,  129.5000,\n",
      "         291.0000,  354.0000,  320.0000,  318.0000,  453.0000,  365.0000,\n",
      "         211.0000,  159.0000,  313.0000,  252.0000,  164.0000,  156.0000,\n",
      "          76.0000,  164.0000,  283.0000,  198.0000,  305.0000,  457.0000,\n",
      "         373.5000,  176.5000], dtype=torch.float64)]\n",
      "[tensor([[14,  0,  1,  ...,  0,  0,  1],\n",
      "        [16,  0,  1,  ...,  1,  1,  0],\n",
      "        [15,  1,  0,  ...,  0,  1,  1],\n",
      "        ...,\n",
      "        [16,  1,  0,  ...,  0,  0,  1],\n",
      "        [15,  0,  0,  ...,  1,  1,  0],\n",
      "        [15,  0,  0,  ...,  1,  0,  0]]), tensor([371.0000, 248.0000, 546.0000, 186.0000, 263.5000, 293.0000, 368.5000,\n",
      "        275.0000, 215.0000, 164.0000, 239.0000, 120.0000, 392.0000,  46.0000,\n",
      "        263.0000, 242.0000, 261.0000, 147.0000, 213.0000, 347.0000, 249.0000,\n",
      "        190.0000, 182.0000, 351.0000, 198.0000, 273.0000, 224.0000, 158.5000,\n",
      "        355.0000, 305.0000, 216.0000, 177.0000, 151.0000, 146.0000, 367.5000,\n",
      "        257.0000, 234.0000, 711.5000, 197.5000, 672.0000, 243.5000, 323.0000,\n",
      "        205.0000, 334.5000, 108.0000, 221.0000, 179.5000, 325.0000, 119.0000,\n",
      "        383.5000,  95.0000, 414.0000, 230.0000, 390.0000, 241.0000, 208.0000,\n",
      "        203.5000, 265.5000, 371.0000, 375.0000, 212.0000, 436.0000, 193.0000,\n",
      "        272.0000, 230.0000, 315.0000, 188.0000, 152.0000, 278.0000, 218.0000,\n",
      "        227.0000, 156.5000, 191.0000, 171.0000, 146.0000, 139.0000, 239.0000,\n",
      "        197.0000,  65.0000, 110.5000, 190.0000, 269.0000, 235.0000,  37.0000,\n",
      "        105.0000, 275.0000, 409.0000, 142.0000, 278.0000, 406.5000, 237.0000,\n",
      "        225.0000, 155.0000, 187.0000, 241.5000, 168.0000, 215.5000, 258.5000,\n",
      "        360.0000, 341.0000, 254.0000, 313.0000,  88.5000, 347.0000, 164.0000,\n",
      "        270.5000, 103.0000, 392.0000, 234.0000, 360.0000, 231.0000, 460.0000,\n",
      "        254.0000, 374.0000, 231.0000, 320.0000, 363.0000, 526.0000, 160.0000,\n",
      "        189.0000, 278.0000, 920.0000, 408.0000, 172.0000, 237.0000, 295.0000,\n",
      "        219.0000, 114.5000, 353.0000, 313.0000, 238.0000, 251.0000,  89.0000,\n",
      "        331.0000, 280.0000, 426.0000, 295.0000, 337.0000, 436.0000, 383.0000,\n",
      "        331.0000, 216.0000, 189.0000, 486.0000,  79.0000, 205.0000, 218.0000,\n",
      "        306.0000, 454.5000, 353.0000, 341.0000, 196.0000,  55.0000, 241.0000,\n",
      "        170.0000, 428.0000, 207.0000, 231.0000, 606.0000, 235.0000, 306.0000,\n",
      "        219.0000, 525.0000,  91.0000, 394.0000, 378.0000,  96.5000, 102.0000,\n",
      "        365.5000, 215.0000, 229.0000, 362.0000, 311.0000, 420.0000, 151.0000,\n",
      "        271.0000, 666.0000, 408.0000,  77.0000, 319.0000, 676.0000, 121.0000,\n",
      "        522.0000, 352.0000, 317.0000, 399.5000,   1.0000, 317.0000, 339.0000,\n",
      "        326.0000, 523.0000, 134.5000, 160.0000, 260.5000, 151.0000, 370.0000,\n",
      "        327.0000, 154.0000, 150.0000, 169.0000, 497.0000, 251.0000, 189.0000,\n",
      "        138.0000, 182.0000, 234.0000, 319.0000, 429.0000, 357.0000, 306.0000,\n",
      "        297.5000, 187.0000, 444.5000, 339.0000, 227.0000, 202.0000, 390.0000,\n",
      "        461.0000, 269.0000, 482.5000, 292.0000,   4.0000, 437.0000, 590.5000,\n",
      "        234.0000, 268.0000, 289.0000, 179.5000, 251.5000, 221.0000, 143.0000,\n",
      "        292.0000, 189.0000, 265.0000, 199.0000, 735.0000, 360.0000, 386.0000,\n",
      "        378.0000, 116.0000, 484.0000, 187.0000, 184.0000, 361.5000, 291.0000,\n",
      "        355.0000, 378.5000, 421.5000, 278.0000, 488.0000, 352.0000, 225.0000,\n",
      "        348.0000, 365.0000, 329.0000,  49.0000], dtype=torch.float64)]\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 100]           2,300\n",
      "              ReLU-2                  [-1, 100]               0\n",
      "            Linear-3                  [-1, 100]          10,100\n",
      "              ReLU-4                  [-1, 100]               0\n",
      "            Linear-5                  [-1, 100]          10,100\n",
      "              ReLU-6                  [-1, 100]               0\n",
      "            Linear-7                   [-1, 50]           5,050\n",
      "              ReLU-8                   [-1, 50]               0\n",
      "            Linear-9                    [-1, 1]              51\n",
      "================================================================\n",
      "Total params: 27,601\n",
      "Trainable params: 27,601\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 0.11\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 536/536 [00:07<00:00, 74.96it/s]\n",
      "Epoch 2/100: 100%|██████████| 536/536 [00:07<00:00, 72.81it/s]\n",
      "Epoch 3/100: 100%|██████████| 536/536 [00:07<00:00, 74.68it/s]\n",
      "Epoch 4/100: 100%|██████████| 536/536 [00:07<00:00, 73.66it/s]\n",
      "Epoch 5/100: 100%|██████████| 536/536 [00:07<00:00, 72.32it/s]\n",
      "Epoch 6/100: 100%|██████████| 536/536 [00:07<00:00, 74.46it/s]\n",
      "Epoch 7/100: 100%|██████████| 536/536 [00:07<00:00, 73.59it/s]\n",
      "Epoch 8/100: 100%|██████████| 536/536 [00:07<00:00, 74.23it/s]\n",
      "Epoch 9/100: 100%|██████████| 536/536 [00:07<00:00, 74.02it/s]\n",
      "Epoch 10/100: 100%|██████████| 536/536 [00:07<00:00, 74.11it/s]\n",
      "Epoch 11/100: 100%|██████████| 536/536 [00:07<00:00, 71.17it/s]\n",
      "Epoch 12/100: 100%|██████████| 536/536 [00:07<00:00, 74.87it/s]\n",
      "Epoch 13/100: 100%|██████████| 536/536 [00:07<00:00, 70.87it/s]\n",
      "Epoch 14/100: 100%|██████████| 536/536 [00:07<00:00, 74.23it/s]\n",
      "Epoch 15/100: 100%|██████████| 536/536 [00:07<00:00, 71.28it/s]\n",
      "Epoch 16/100: 100%|██████████| 536/536 [00:07<00:00, 75.34it/s]\n",
      "Epoch 17/100: 100%|██████████| 536/536 [00:07<00:00, 72.67it/s]\n",
      "Epoch 18/100: 100%|██████████| 536/536 [00:07<00:00, 73.04it/s]\n",
      "Epoch 19/100: 100%|██████████| 536/536 [00:07<00:00, 73.10it/s]\n",
      "Epoch 20/100: 100%|██████████| 536/536 [00:07<00:00, 72.43it/s]\n",
      "Epoch 21/100: 100%|██████████| 536/536 [00:07<00:00, 72.65it/s]\n",
      "Epoch 22/100: 100%|██████████| 536/536 [00:07<00:00, 72.04it/s]\n",
      "Epoch 23/100: 100%|██████████| 536/536 [00:07<00:00, 73.58it/s]\n",
      "Epoch 24/100: 100%|██████████| 536/536 [00:07<00:00, 71.39it/s]\n",
      "Epoch 25/100: 100%|██████████| 536/536 [00:07<00:00, 73.20it/s]\n",
      "Epoch 26/100: 100%|██████████| 536/536 [00:07<00:00, 70.99it/s]\n",
      "Epoch 27/100: 100%|██████████| 536/536 [00:07<00:00, 73.66it/s]\n",
      "Epoch 28/100: 100%|██████████| 536/536 [00:07<00:00, 71.38it/s]\n",
      "Epoch 29/100: 100%|██████████| 536/536 [00:07<00:00, 73.38it/s]\n",
      "Epoch 30/100: 100%|██████████| 536/536 [00:07<00:00, 73.25it/s]\n",
      "Epoch 31/100: 100%|██████████| 536/536 [00:07<00:00, 71.79it/s]\n",
      "Epoch 32/100: 100%|██████████| 536/536 [00:07<00:00, 70.73it/s]\n",
      "Epoch 33/100: 100%|██████████| 536/536 [00:07<00:00, 72.96it/s]\n",
      "Epoch 34/100: 100%|██████████| 536/536 [00:07<00:00, 72.33it/s]\n",
      "Epoch 35/100: 100%|██████████| 536/536 [00:07<00:00, 71.97it/s]\n",
      "Epoch 36/100: 100%|██████████| 536/536 [00:07<00:00, 74.14it/s]\n",
      "Epoch 37/100: 100%|██████████| 536/536 [00:07<00:00, 71.29it/s]\n",
      "Epoch 38/100: 100%|██████████| 536/536 [00:07<00:00, 73.71it/s]\n",
      "Epoch 39/100: 100%|██████████| 536/536 [00:07<00:00, 70.32it/s]\n",
      "Epoch 40/100: 100%|██████████| 536/536 [00:07<00:00, 73.95it/s]\n",
      "Epoch 41/100: 100%|██████████| 536/536 [00:07<00:00, 70.45it/s]\n",
      "Epoch 42/100: 100%|██████████| 536/536 [00:07<00:00, 72.15it/s]\n",
      "Epoch 43/100: 100%|██████████| 536/536 [00:07<00:00, 72.07it/s]\n",
      "Epoch 44/100: 100%|██████████| 536/536 [00:07<00:00, 72.82it/s]\n",
      "Epoch 45/100: 100%|██████████| 536/536 [00:07<00:00, 70.09it/s]\n",
      "Epoch 46/100: 100%|██████████| 536/536 [00:07<00:00, 70.13it/s]\n",
      "Epoch 47/100: 100%|██████████| 536/536 [00:07<00:00, 71.55it/s]\n",
      "Epoch 48/100: 100%|██████████| 536/536 [00:07<00:00, 71.74it/s]\n",
      "Epoch 49/100: 100%|██████████| 536/536 [00:07<00:00, 70.89it/s]\n",
      "Epoch 50/100: 100%|██████████| 536/536 [00:07<00:00, 70.36it/s]\n",
      "Epoch 51/100: 100%|██████████| 536/536 [00:07<00:00, 72.30it/s]\n",
      "Epoch 52/100: 100%|██████████| 536/536 [00:07<00:00, 70.83it/s]\n",
      "Epoch 53/100: 100%|██████████| 536/536 [00:07<00:00, 71.95it/s]\n",
      "Epoch 54/100: 100%|██████████| 536/536 [00:07<00:00, 71.77it/s]\n",
      "Epoch 55/100: 100%|██████████| 536/536 [00:07<00:00, 72.80it/s]\n",
      "Epoch 56/100: 100%|██████████| 536/536 [00:07<00:00, 70.88it/s]\n",
      "Epoch 57/100: 100%|██████████| 536/536 [00:07<00:00, 71.50it/s]\n",
      "Epoch 58/100: 100%|██████████| 536/536 [00:07<00:00, 70.95it/s]\n",
      "Epoch 59/100: 100%|██████████| 536/536 [00:07<00:00, 71.32it/s]\n",
      "Epoch 60/100: 100%|██████████| 536/536 [00:07<00:00, 70.03it/s]\n",
      "Epoch 61/100: 100%|██████████| 536/536 [00:07<00:00, 69.18it/s]\n",
      "Epoch 62/100: 100%|██████████| 536/536 [00:07<00:00, 71.16it/s]\n",
      "Epoch 63/100: 100%|██████████| 536/536 [00:07<00:00, 71.05it/s]\n",
      "Epoch 64/100: 100%|██████████| 536/536 [00:07<00:00, 71.14it/s]\n",
      "Epoch 65/100: 100%|██████████| 536/536 [00:07<00:00, 70.06it/s]\n",
      "Epoch 66/100: 100%|██████████| 536/536 [00:07<00:00, 70.47it/s]\n",
      "Epoch 67/100: 100%|██████████| 536/536 [00:07<00:00, 70.78it/s]\n",
      "Epoch 68/100: 100%|██████████| 536/536 [00:07<00:00, 69.53it/s]\n",
      "Epoch 69/100: 100%|██████████| 536/536 [00:07<00:00, 70.59it/s]\n",
      "Epoch 70/100: 100%|██████████| 536/536 [00:07<00:00, 69.45it/s]\n",
      "Epoch 71/100: 100%|██████████| 536/536 [00:07<00:00, 70.12it/s]\n",
      "Epoch 72/100: 100%|██████████| 536/536 [00:07<00:00, 69.66it/s]\n",
      "Epoch 73/100: 100%|██████████| 536/536 [00:07<00:00, 71.24it/s]\n",
      "Epoch 74/100: 100%|██████████| 536/536 [00:07<00:00, 70.88it/s]\n",
      "Epoch 75/100: 100%|██████████| 536/536 [00:07<00:00, 70.55it/s]\n",
      "Epoch 76/100: 100%|██████████| 536/536 [00:07<00:00, 70.72it/s]\n",
      "Epoch 77/100: 100%|██████████| 536/536 [00:07<00:00, 69.23it/s]\n",
      "Epoch 78/100: 100%|██████████| 536/536 [00:07<00:00, 71.22it/s]\n",
      "Epoch 79/100: 100%|██████████| 536/536 [00:07<00:00, 68.78it/s]\n",
      "Epoch 80/100: 100%|██████████| 536/536 [00:07<00:00, 71.10it/s]\n",
      "Epoch 81/100: 100%|██████████| 536/536 [00:07<00:00, 68.99it/s]\n",
      "Epoch 82/100: 100%|██████████| 536/536 [00:07<00:00, 72.11it/s]\n",
      "Epoch 83/100: 100%|██████████| 536/536 [00:07<00:00, 68.72it/s]\n",
      "Epoch 84/100: 100%|██████████| 536/536 [00:07<00:00, 70.93it/s]\n",
      "Epoch 85/100: 100%|██████████| 536/536 [00:07<00:00, 68.13it/s]\n",
      "Epoch 86/100: 100%|██████████| 536/536 [00:07<00:00, 72.04it/s]\n",
      "Epoch 87/100: 100%|██████████| 536/536 [00:07<00:00, 69.16it/s]\n",
      "Epoch 88/100: 100%|██████████| 536/536 [00:07<00:00, 71.67it/s]\n",
      "Epoch 89/100: 100%|██████████| 536/536 [00:07<00:00, 68.43it/s]\n",
      "Epoch 90/100: 100%|██████████| 536/536 [00:07<00:00, 70.37it/s]\n",
      "Epoch 91/100: 100%|██████████| 536/536 [00:07<00:00, 70.89it/s]\n",
      "Epoch 92/100: 100%|██████████| 536/536 [00:07<00:00, 69.45it/s]\n",
      "Epoch 93/100: 100%|██████████| 536/536 [00:07<00:00, 70.77it/s]\n",
      "Epoch 94/100: 100%|██████████| 536/536 [00:07<00:00, 68.83it/s]\n",
      "Epoch 95/100: 100%|██████████| 536/536 [00:07<00:00, 71.19it/s]\n",
      "Epoch 96/100: 100%|██████████| 536/536 [00:07<00:00, 68.85it/s]\n",
      "Epoch 97/100: 100%|██████████| 536/536 [00:07<00:00, 70.44it/s]\n",
      "Epoch 98/100: 100%|██████████| 536/536 [00:07<00:00, 68.35it/s]\n",
      "Epoch 99/100: 100%|██████████| 536/536 [00:07<00:00, 70.23it/s]\n",
      "Epoch 100/100: 100%|██████████| 536/536 [00:08<00:00, 66.15it/s]\n",
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100/100 -- Training loss 162740121.52238807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([187])) that is different to the input size (torch.Size([187, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([175])) that is different to the input size (torch.Size([175, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 20641.210256092585\n",
      "RMSE train : 127.5260806843354\n",
      "RMSE test : 128.2096122014373\n",
      "MAE train : 94.02023373596421\n",
      "MAE test : 94.26319705983676\n",
      "-----------------------------------------------------\n",
      "year 2022\n",
      "-----------------------------------------------------\n",
      "(342634, 40)\n",
      "cols_to_remove ['TurnoutTimeSeconds_min', 'TurnoutTimeSeconds_mean', 'TurnoutTimeSeconds_max', 'TravelTimeSeconds_min', 'TravelTimeSeconds_mean', 'TravelTimeSeconds_max', 'PumpSecondsOnSite_min', 'PumpSecondsOnSite_mean', 'PumpSecondsOnSite_max', 'PumpSecondsOnSite_min', 'PumpSecondsOnSite_mean', 'PumpSecondsOnSite_max', 'NumPumpsAttending']\n",
      "cols_to_keep ['CalYear', 'PropertyType_0', 'PropertyType_1', 'PropertyType_2', 'PropertyType_3', 'PropertyType_4', 'PropertyType_5', 'PropertyType_6', 'StopCode_0', 'StopCode_1', 'StopCode_2', 'StopCode_3', 'StopCode_4']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalYear</th>\n",
       "      <th>PropertyType_0</th>\n",
       "      <th>PropertyType_1</th>\n",
       "      <th>PropertyType_2</th>\n",
       "      <th>PropertyType_3</th>\n",
       "      <th>PropertyType_4</th>\n",
       "      <th>PropertyType_5</th>\n",
       "      <th>PropertyType_6</th>\n",
       "      <th>StopCode_0</th>\n",
       "      <th>StopCode_1</th>\n",
       "      <th>StopCode_2</th>\n",
       "      <th>StopCode_3</th>\n",
       "      <th>StopCode_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1248893</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248894</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CalYear  PropertyType_0  PropertyType_1  PropertyType_2  \\\n",
       "1248893       14               0               0               0   \n",
       "1248894       14               0               1               1   \n",
       "\n",
       "         PropertyType_3  PropertyType_4  PropertyType_5  PropertyType_6  \\\n",
       "1248893               0               0               1               0   \n",
       "1248894               1               1               0               0   \n",
       "\n",
       "         StopCode_0  StopCode_1  StopCode_2  StopCode_3  StopCode_4  \n",
       "1248893           0           0           0           1           1  \n",
       "1248894           0           0           0           1           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342634, 13)\n",
      "--------------------------------------------------------------------------------\n",
      "/////////////////////////// cible PumpSecondsOnSite_mean\n",
      "[tensor([[15,  0,  0,  ...,  1,  0,  1],\n",
      "        [16,  0,  0,  ...,  1,  0,  0],\n",
      "        [16,  0,  0,  ...,  0,  1,  1],\n",
      "        ...,\n",
      "        [15,  0,  0,  ...,  0,  0,  0],\n",
      "        [16,  0,  0,  ...,  0,  1,  1],\n",
      "        [16,  0,  0,  ...,  0,  0,  0]]), tensor([2100., 1260.,  720., 1560.,  180.,  240.,  480.,  300.,  180., 2340.,\n",
      "         300.,  300., 2040.,  480.,  240.,  600.,  570., 1560.,  240.,  240.,\n",
      "         120.,  450.,  810.,  840.,   60., 1380.,  660.,  330., 1500.,  120.,\n",
      "        1080.,  300.,  450.,  780.,  510.,  120., 3900.,  540., 2340.,  420.,\n",
      "         780.,   60., 1140.,  300.,  480., 5160., 2100.,  990., 1140.,  480.,\n",
      "         660., 1560.,  600.,  960.,  300.,  240.,  420.,   90., 1860., 1800.,\n",
      "         840.,  300.,  180., 9120., 2040.,  900.,  240.,    0.,  120.,  420.,\n",
      "          60.,  240.,  330.,   60., 1200., 3900.,  540., 1320., 1980., 1200.,\n",
      "         480.,  780., 2520.,  780.,  900.,  300.,  960.,  480.,  660.,  120.,\n",
      "        1020.,  480.,  720., 1080.,  240.,  840.,  210., 1080.,  600., 1200.,\n",
      "         750., 1500., 1440., 2880.,  420.,  600., 3660.,  660.,  270., 5040.,\n",
      "         240.,  480., 1680.,  540.,  600., 1440.,  270.,  960.,  330.,  840.,\n",
      "         420., 6660.,  660., 1740.,  480.,  840., 1500.,  240.,  900., 1020.,\n",
      "         210.,  960.,  720.,  120., 1800., 1860., 1440.,  300.,  240.,   60.,\n",
      "        6750.,  420.,  330.,  120., 6000.,  360., 1200.,  180., 1260.,  780.,\n",
      "         810.,  300.,  600.,  360.,   90.,  720.,  900., 1440.,  420., 5160.,\n",
      "         180.,  840.,  180.,  840., 1110., 2100.,  330.,  240., 1170.,  360.,\n",
      "         180.,  540., 1440.,  420.,  120.,  660.,  840.,  300.,  180.,  480.,\n",
      "        2160.,  210.,  180.,  210.,  720., 3300., 1080.,  180., 1680.,  390.,\n",
      "         360.,  660., 2040.,  240.,  180.,  420.,  480., 1470., 1260.,  270.,\n",
      "         420.,  360.,  600., 1140.,  360.,  450.,  300., 2160.,  180., 1080.,\n",
      "        1200.,  480., 3480.,  360.,  840.,  900.,  480.,  420.,  660.,  300.,\n",
      "          60.,  840., 1500., 1260.,  660.,  720.,  930., 1320., 1920.,  360.,\n",
      "        3900.,  720.,  240.,  840.,  540.,  240.,  480., 1200.,  840., 4260.,\n",
      "         300.,   60.,  540., 1500.,  780.,  180., 2010.,   60.,  840.,  360.,\n",
      "        2190.,  180.,  150.,  120.,  480.,  240., 3600.,  120., 2460.,  480.,\n",
      "        3720.,  180., 2220., 1320.,  480.,  420., 2100.,  390.,  180., 1080.,\n",
      "        2940.,  180.,  420.,  900., 9000.,  570., 1020., 2220.,  480., 5400.,\n",
      "        1380.,  600., 1620.,  360.,  870.,  150., 1560.,  360.,  480.,  510.,\n",
      "         540.,  540.,  180., 2040., 3360.,  480.,  840.,  240.,  240., 7380.,\n",
      "         120.,  840.,  990.,  240.,  240.,  180.,  240.,  780., 1380.,  540.,\n",
      "         660., 1140.,  960., 1380.,  300.,  360.,  330.,  300.,  180., 3180.,\n",
      "         360., 2970., 1560.,  300.,  600., 1620.,   60.,  360., 1380., 2040.,\n",
      "         240.,  300.,  450.,  540.,  330.,  660.,  960., 1500., 5940., 3240.,\n",
      "         300.,  450.,  600., 1860.,  780.,  240.,  480., 1260.,  600., 5940.,\n",
      "         480., 5580.,  600.,  480.,  990.,  240.,  360.,  660.,  840.,  150.,\n",
      "        1680., 2160.,  180., 1680., 4680.,  420.,  720.,  300., 1200.,  420.,\n",
      "         300.,  300.,  540.,  420.,  840., 1290.,  120.,  600.,  270., 1560.,\n",
      "         780., 2160., 5640.,  660.,  360.,  360.,  240.,  960., 1440.,  180.,\n",
      "        3300., 1020., 2160.,  240.,  600., 4500.,  300.,  120., 1020.,  300.,\n",
      "         420.,  960.,  420.,  780., 1320.,  480.,  720.,  480.,  960.,  360.,\n",
      "        2040., 1830.,   90.,  750.,  300.,  540.,  360., 1020.,  240.,  660.,\n",
      "         960., 1950., 1140., 1080.,  240., 4680., 1200.,  240., 1140.,  660.,\n",
      "        1260., 2520.,  840.,  390.,  240., 1230.,  300.,  180.,  480., 1620.,\n",
      "         840.,  210., 1020., 6450.,  540.,  180.,  930., 3750.,  960.,  720.,\n",
      "        5580., 2520., 2430.,  780.,  660., 3660.,  900.,  480., 4200.,  270.,\n",
      "         360.,  720.,  420.,  300.,  600.,  300.,  660., 9210., 1380., 2070.,\n",
      "         360., 1140., 1020.,  480.,  240.,  900.,  720.,  180., 1260.,  960.,\n",
      "         660., 1200.,  240.,  780.,  360.,  240.,  180., 1500., 1440.,  600.,\n",
      "        1740.,  120.,  120.,  480.,  780., 2460.,  120.,  660.,  360.,  420.,\n",
      "         180.,  180., 4140.,  720., 2220.,  450.,   90.,  180., 3420.,  900.,\n",
      "         870.,  360.], dtype=torch.float64)]\n",
      "[tensor([[14,  0,  0,  ...,  1,  1,  0],\n",
      "        [16,  0,  0,  ...,  1,  0,  1],\n",
      "        [15,  0,  0,  ...,  0,  1,  1],\n",
      "        ...,\n",
      "        [16,  0,  0,  ...,  1,  0,  1],\n",
      "        [15,  0,  0,  ...,  1,  0,  1],\n",
      "        [15,  0,  0,  ...,  0,  1,  1]]), tensor([  540.,   900.,   630.,  1020.,   450.,   540.,   180.,   960.,   180.,\n",
      "          540.,   570.,  1440.,   840.,    60.,   480.,   300.,   780.,   480.,\n",
      "          420.,   360.,   840.,   480.,   360.,   390.,   360.,  2700.,   240.,\n",
      "         1230.,   120.,  1020.,  1080.,   180.,   900.,   300.,   720.,   120.,\n",
      "         1380.,   360.,   600.,   540.,   930.,   480.,   540.,   480.,   660.,\n",
      "          420.,   270.,  1140.,  1200.,   120.,   360.,   150.,   900.,  2010.,\n",
      "          720.,   240.,   300.,   150.,   660.,   150.,  1560.,   720.,   660.,\n",
      "         1080.,   300.,   360.,    60.,  6300.,   150.,   300.,   600.,   330.,\n",
      "          780.,   600.,  1260.,   240.,   600.,  1020.,   600.,  1020.,  3060.,\n",
      "           60.,   480.,  1320.,  1200.,   120.,   180.,     0.,   720.,   270.,\n",
      "          270.,   210.,   360.,   300.,  8910.,   900.,   180.,   780.,   240.,\n",
      "          600.,  1050.,   180.,   210.,   120.,   180.,  2610.,   960.,   420.,\n",
      "          420.,   510.,   240.,   240.,  1320.,   900.,  1800.,  1320.,   420.,\n",
      "          660.,  3120.,  1200.,   420.,  1080.,   180.,    60.,   720.,   420.,\n",
      "          270.,  5940.,   510.,  3960.,   180.,   600.,   300.,  1500.,   360.,\n",
      "          480.,   480.,  1200.,   120.,   240.,   600.,   480.,   540.,  2160.,\n",
      "          600.,   780.,   840.,   210.,   630.,   180.,  1500.,  1020.,   300.,\n",
      "          960.,   180.,   300.,   540.,   720.,   960.,  1020.,   900.,  4860.,\n",
      "         1080.,   420.,   300.,   960.,   960.,  1560.,   360.,  1320.,   420.,\n",
      "          600.,   660.,   660.,   480.,   840.,   180.,   150.,   540.,  1440.,\n",
      "         1080.,  1290.,   600.,   900.,  1320.,   360.,   900.,   180.,  1260.,\n",
      "          660.,  1440.,   330.,   780.,   570.,  3660.,  1260.,   360.,   300.,\n",
      "         2400.,   360.,   660., 12840.,   420.,   120.,   420.,  1410.,  1560.,\n",
      "          450.,  1050.,   660.,   420.,   480.,   810.,   480.,  1380.,  1200.,\n",
      "          120.,   180.,   960.,  2430.,   660.,   240.,  1920.,    60.,   180.,\n",
      "          960.,  9390.,   300.,   330.,   270.,   420.,   600.,   180.,   420.,\n",
      "          840.,   960.,   480.,   510.,  2220.,   420.,  1620.,   420.,   840.,\n",
      "          300.,  2040.,  2460.,   690.,   180.,  9000.,  1020.,   120.,   480.,\n",
      "          840.,  1920.,  1320.,  1320.], dtype=torch.float64)]\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 100]           1,400\n",
      "              ReLU-2                  [-1, 100]               0\n",
      "            Linear-3                  [-1, 100]          10,100\n",
      "              ReLU-4                  [-1, 100]               0\n",
      "            Linear-5                  [-1, 100]          10,100\n",
      "              ReLU-6                  [-1, 100]               0\n",
      "            Linear-7                   [-1, 50]           5,050\n",
      "              ReLU-8                   [-1, 50]               0\n",
      "            Linear-9                    [-1, 1]              51\n",
      "================================================================\n",
      "Total params: 26,701\n",
      "Trainable params: 26,701\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 0.11\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 536/536 [00:07<00:00, 72.57it/s]\n",
      "Epoch 2/100: 100%|██████████| 536/536 [00:07<00:00, 73.78it/s]\n",
      "Epoch 3/100: 100%|██████████| 536/536 [00:07<00:00, 73.38it/s]\n",
      "Epoch 4/100: 100%|██████████| 536/536 [00:07<00:00, 73.39it/s]\n",
      "Epoch 5/100: 100%|██████████| 536/536 [00:07<00:00, 74.14it/s]\n",
      "Epoch 6/100: 100%|██████████| 536/536 [00:07<00:00, 73.57it/s]\n",
      "Epoch 7/100: 100%|██████████| 536/536 [00:07<00:00, 73.95it/s]\n",
      "Epoch 8/100: 100%|██████████| 536/536 [00:07<00:00, 72.62it/s]\n",
      "Epoch 9/100: 100%|██████████| 536/536 [00:07<00:00, 74.02it/s]\n",
      "Epoch 10/100: 100%|██████████| 536/536 [00:07<00:00, 73.12it/s]\n",
      "Epoch 11/100: 100%|██████████| 536/536 [00:07<00:00, 72.81it/s]\n",
      "Epoch 12/100: 100%|██████████| 536/536 [00:07<00:00, 74.05it/s]\n",
      "Epoch 13/100: 100%|██████████| 536/536 [00:07<00:00, 72.80it/s]\n",
      "Epoch 14/100: 100%|██████████| 536/536 [00:07<00:00, 73.67it/s]\n",
      "Epoch 15/100: 100%|██████████| 536/536 [00:07<00:00, 73.02it/s]\n",
      "Epoch 16/100: 100%|██████████| 536/536 [00:07<00:00, 72.82it/s]\n",
      "Epoch 17/100: 100%|██████████| 536/536 [00:07<00:00, 72.38it/s]\n",
      "Epoch 18/100: 100%|██████████| 536/536 [00:07<00:00, 72.96it/s]\n",
      "Epoch 19/100: 100%|██████████| 536/536 [00:07<00:00, 73.58it/s]\n",
      "Epoch 20/100: 100%|██████████| 536/536 [00:07<00:00, 73.46it/s]\n",
      "Epoch 21/100: 100%|██████████| 536/536 [00:07<00:00, 71.88it/s]\n",
      "Epoch 22/100: 100%|██████████| 536/536 [00:07<00:00, 74.06it/s]\n",
      "Epoch 23/100: 100%|██████████| 536/536 [00:07<00:00, 73.00it/s]\n",
      "Epoch 24/100: 100%|██████████| 536/536 [00:07<00:00, 71.99it/s]\n",
      "Epoch 25/100: 100%|██████████| 536/536 [00:07<00:00, 72.25it/s]\n",
      "Epoch 26/100: 100%|██████████| 536/536 [00:07<00:00, 72.48it/s]\n",
      "Epoch 27/100: 100%|██████████| 536/536 [00:07<00:00, 72.40it/s]\n",
      "Epoch 28/100: 100%|██████████| 536/536 [00:07<00:00, 72.89it/s]\n",
      "Epoch 29/100: 100%|██████████| 536/536 [00:07<00:00, 71.92it/s]\n",
      "Epoch 30/100: 100%|██████████| 536/536 [00:07<00:00, 72.38it/s]\n",
      "Epoch 31/100: 100%|██████████| 536/536 [00:07<00:00, 72.05it/s]\n",
      "Epoch 32/100: 100%|██████████| 536/536 [00:07<00:00, 71.22it/s]\n",
      "Epoch 33/100: 100%|██████████| 536/536 [00:07<00:00, 73.06it/s]\n",
      "Epoch 34/100: 100%|██████████| 536/536 [00:07<00:00, 72.32it/s]\n",
      "Epoch 35/100: 100%|██████████| 536/536 [00:07<00:00, 70.50it/s]\n",
      "Epoch 36/100: 100%|██████████| 536/536 [00:07<00:00, 71.93it/s]\n",
      "Epoch 37/100: 100%|██████████| 536/536 [00:07<00:00, 72.36it/s]\n",
      "Epoch 38/100: 100%|██████████| 536/536 [00:07<00:00, 72.55it/s]\n",
      "Epoch 39/100: 100%|██████████| 536/536 [00:07<00:00, 70.91it/s]\n",
      "Epoch 40/100: 100%|██████████| 536/536 [00:07<00:00, 71.04it/s]\n",
      "Epoch 41/100: 100%|██████████| 536/536 [00:07<00:00, 72.01it/s]\n",
      "Epoch 42/100: 100%|██████████| 536/536 [00:07<00:00, 71.07it/s]\n",
      "Epoch 43/100: 100%|██████████| 536/536 [00:07<00:00, 71.44it/s]\n",
      "Epoch 44/100: 100%|██████████| 536/536 [00:07<00:00, 72.26it/s]\n",
      "Epoch 45/100: 100%|██████████| 536/536 [00:07<00:00, 71.79it/s]\n",
      "Epoch 46/100: 100%|██████████| 536/536 [00:07<00:00, 71.85it/s]\n",
      "Epoch 47/100: 100%|██████████| 536/536 [00:07<00:00, 73.40it/s]\n",
      "Epoch 48/100: 100%|██████████| 536/536 [00:07<00:00, 70.97it/s]\n",
      "Epoch 49/100: 100%|██████████| 536/536 [00:07<00:00, 72.17it/s]\n",
      "Epoch 50/100: 100%|██████████| 536/536 [00:07<00:00, 71.23it/s]\n",
      "Epoch 51/100: 100%|██████████| 536/536 [00:07<00:00, 72.00it/s]\n",
      "Epoch 52/100: 100%|██████████| 536/536 [00:07<00:00, 71.58it/s]\n",
      "Epoch 53/100: 100%|██████████| 536/536 [00:07<00:00, 71.96it/s]\n",
      "Epoch 54/100: 100%|██████████| 536/536 [00:07<00:00, 71.60it/s]\n",
      "Epoch 55/100: 100%|██████████| 536/536 [00:07<00:00, 71.37it/s]\n",
      "Epoch 56/100: 100%|██████████| 536/536 [00:07<00:00, 71.34it/s]\n",
      "Epoch 57/100: 100%|██████████| 536/536 [00:07<00:00, 70.80it/s]\n",
      "Epoch 58/100: 100%|██████████| 536/536 [00:07<00:00, 72.50it/s]\n",
      "Epoch 59/100: 100%|██████████| 536/536 [00:07<00:00, 69.71it/s]\n",
      "Epoch 60/100: 100%|██████████| 536/536 [00:07<00:00, 72.76it/s]\n",
      "Epoch 61/100: 100%|██████████| 536/536 [00:07<00:00, 70.18it/s]\n",
      "Epoch 62/100: 100%|██████████| 536/536 [00:07<00:00, 72.21it/s]\n",
      "Epoch 63/100: 100%|██████████| 536/536 [00:07<00:00, 70.63it/s]\n",
      "Epoch 64/100: 100%|██████████| 536/536 [00:07<00:00, 70.59it/s]\n",
      "Epoch 65/100: 100%|██████████| 536/536 [00:07<00:00, 70.50it/s]\n",
      "Epoch 66/100: 100%|██████████| 536/536 [00:07<00:00, 71.42it/s]\n",
      "Epoch 67/100: 100%|██████████| 536/536 [00:07<00:00, 70.56it/s]\n",
      "Epoch 68/100: 100%|██████████| 536/536 [00:07<00:00, 71.55it/s]\n",
      "Epoch 69/100: 100%|██████████| 536/536 [00:07<00:00, 70.98it/s]\n",
      "Epoch 70/100: 100%|██████████| 536/536 [00:07<00:00, 71.17it/s]\n",
      "Epoch 71/100: 100%|██████████| 536/536 [00:07<00:00, 72.39it/s]\n",
      "Epoch 72/100: 100%|██████████| 536/536 [00:07<00:00, 69.06it/s]\n",
      "Epoch 73/100: 100%|██████████| 536/536 [00:07<00:00, 71.79it/s]\n",
      "Epoch 74/100: 100%|██████████| 536/536 [00:07<00:00, 70.07it/s]\n",
      "Epoch 75/100: 100%|██████████| 536/536 [00:07<00:00, 72.52it/s]\n",
      "Epoch 76/100: 100%|██████████| 536/536 [00:07<00:00, 69.16it/s]\n",
      "Epoch 77/100: 100%|██████████| 536/536 [00:07<00:00, 71.91it/s]\n",
      "Epoch 78/100: 100%|██████████| 536/536 [00:07<00:00, 69.94it/s]\n",
      "Epoch 79/100: 100%|██████████| 536/536 [00:07<00:00, 71.33it/s]\n",
      "Epoch 80/100: 100%|██████████| 536/536 [00:07<00:00, 69.20it/s]\n",
      "Epoch 81/100: 100%|██████████| 536/536 [00:07<00:00, 71.68it/s]\n",
      "Epoch 82/100: 100%|██████████| 536/536 [00:07<00:00, 71.38it/s]\n",
      "Epoch 83/100: 100%|██████████| 536/536 [00:07<00:00, 70.23it/s]\n",
      "Epoch 84/100: 100%|██████████| 536/536 [00:07<00:00, 71.20it/s]\n",
      "Epoch 85/100: 100%|██████████| 536/536 [00:07<00:00, 71.27it/s]\n",
      "Epoch 86/100: 100%|██████████| 536/536 [00:07<00:00, 71.83it/s]\n",
      "Epoch 87/100: 100%|██████████| 536/536 [00:07<00:00, 69.59it/s]\n",
      "Epoch 88/100: 100%|██████████| 536/536 [00:07<00:00, 71.82it/s]\n",
      "Epoch 89/100: 100%|██████████| 536/536 [00:07<00:00, 69.90it/s]\n",
      "Epoch 90/100: 100%|██████████| 536/536 [00:07<00:00, 71.67it/s]\n",
      "Epoch 91/100: 100%|██████████| 536/536 [00:07<00:00, 69.29it/s]\n",
      "Epoch 92/100: 100%|██████████| 536/536 [00:07<00:00, 71.68it/s]\n",
      "Epoch 93/100: 100%|██████████| 536/536 [00:07<00:00, 69.13it/s]\n",
      "Epoch 94/100: 100%|██████████| 536/536 [00:07<00:00, 72.64it/s]\n",
      "Epoch 95/100: 100%|██████████| 536/536 [00:07<00:00, 71.29it/s]\n",
      "Epoch 96/100: 100%|██████████| 536/536 [00:07<00:00, 70.14it/s]\n",
      "Epoch 97/100: 100%|██████████| 536/536 [00:07<00:00, 70.06it/s]\n",
      "Epoch 98/100: 100%|██████████| 536/536 [00:07<00:00, 70.90it/s]\n",
      "Epoch 99/100: 100%|██████████| 536/536 [00:07<00:00, 70.68it/s]\n",
      "Epoch 100/100: 100%|██████████| 536/536 [00:07<00:00, 70.51it/s]\n",
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100/100 -- Training loss 16875108454.208956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([187])) that is different to the input size (torch.Size([187, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2652929.0475746267\n",
      "RMSE train : 1296.6751493869788\n",
      "RMSE test : 1294.5039316807713\n",
      "MAE train : 702.3303524746951\n",
      "MAE test : 707.3933636893315\n",
      "[{'Target': 'TurnoutTimeSeconds_mean', 'Year floor': 2022, 'Loss': 1598.6247834162925, 'RMSE train': 34.18922020415068, 'RMSE test': 34.473754602898055, 'MAE train': 22.002475214264933, 'MAE test': 22.068980878012514}, {'Target': 'TravelTimeSeconds_mean', 'Year floor': 2022, 'Loss': 20641.210256092585, 'RMSE train': 127.5260806843354, 'RMSE test': 128.2096122014373, 'MAE train': 94.02023373596421, 'MAE test': 94.26319705983676}, {'Target': 'PumpSecondsOnSite_mean', 'Year floor': 2022, 'Loss': 2652929.0475746267, 'RMSE train': 1296.6751493869788, 'RMSE test': 1294.5039316807713, 'MAE train': 702.3303524746951, 'MAE test': 707.3933636893315}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lordb\\anaconda3\\envs\\projet-IA-312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([175])) that is different to the input size (torch.Size([175, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------- Pytorch régression\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    ")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Colonnes cibles\n",
    "cols_cible = [\n",
    "    [\"TurnoutTimeSeconds_min\", \"TurnoutTimeSeconds_mean\", \"TurnoutTimeSeconds_max\"],\n",
    "    [\"TravelTimeSeconds_min\", \"TravelTimeSeconds_mean\", \"TravelTimeSeconds_max\"],\n",
    "    [\"PumpSecondsOnSite_min\", \"PumpSecondsOnSite_mean\", \"PumpSecondsOnSite_max\"],\n",
    "]\n",
    "#Filtre sur les colonnes cibles(xxx_mean)\n",
    "cols_cible_filter = [\n",
    "    \"TurnoutTimeSeconds_mean\",\n",
    "    \"TravelTimeSeconds_mean\",\n",
    "    \"PumpSecondsOnSite_mean\",\n",
    "]\n",
    "# Détermine si le GPU est disponible, sinon utilise le CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device utilisé :\", device)\n",
    "# Definir Taille du lot d'entraînement\n",
    "train_batch_size = 512\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Classe personnalisée pour les données d'entraînement.\n",
    "    \n",
    "    Paramètres :\n",
    "    X (pandas.DataFrame) : Les caractéristiques (features) des données.\n",
    "    y (pandas.Series) : Les étiquettes (labels) des données.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retourne une paire (x, y) pour un index donné.\n",
    "        \n",
    "        Paramètres :\n",
    "        idx (int) : L'index de la donnée.\n",
    "        \n",
    "        Retourne :\n",
    "        list : Une liste contenant la caractéristique (x) et l'étiquette (y).\n",
    "        \"\"\"\n",
    "        # Pour chaque donnée, retourner [x, y]\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return [x, y]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Retourne la longueur du dataset.\n",
    "        \n",
    "        Retourne :\n",
    "        int : Le nombre total de données dans le dataset.\n",
    "        \"\"\"\n",
    "        return len(self.X)\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"\n",
    "    Crée et retourne un modèle séquentiel de réseau de neurones.\n",
    "\n",
    "    Retourne :\n",
    "    torch.nn.Sequential : Le modèle de réseau de neurones.\n",
    "    \"\"\"\n",
    "    #Crée un modèle séquentiel de réseau de neurones avec plusieurs couches linéaires et des fonctions d'activation ReLU.\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(X.shape[1], 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 1),\n",
    "    )\n",
    "    #Le modèle est déplacé vers le dispositif approprié (GPU ou CPU)\n",
    "    model.to(device)\n",
    "    #affiche un résumé du modèle avec la taille de l'entrée spécifiée\n",
    "    #par input_size=(X.shape[-1],) et le dispositif device\n",
    "    summary(model, input_size=(X.shape[-1],), device=device)\n",
    "    #retourne le model créé\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_loader):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle de réseau de neurones sur les données fournies.\n",
    "\n",
    "    Paramètres :\n",
    "    model (torch.nn.Module) : Le modèle de réseau de neurones à entraîner.\n",
    "    train_loader (torch.utils.data.DataLoader) : Le DataLoader contenant les données d'entraînement.\n",
    "\n",
    "    Retourne :\n",
    "    torch.nn.Module : La fonction de perte utilisée pour l'entraînement.\n",
    "    \"\"\"\n",
    "    epochs = 100\n",
    "    # Définition de l'optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "    # Définition de la fonction de perte\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Dans ce mode certaines couches du modèle agissent différemment\n",
    "        #entrainement du modele\n",
    "        model.train()\n",
    "        loss_total = 0\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\", position=0, leave=True) as pbar_epoch:\n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                with tqdm(total=train_batch_size, desc=f\"Batch {batch_idx+1}\", position=1, leave=False) as pbar_batch:\n",
    "                    # Recupere le Batch de données\n",
    "                    X_batch, y_batch = batch\n",
    "                    # Envoi les données au device (GPU ou CPU)\n",
    "                    X_batch = X_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    # Gradient mis à 0\n",
    "                    model.zero_grad()\n",
    "                    # Calcul de prédiction\n",
    "                    y_pred = model(X_batch.to(torch.float32))[:,0]\n",
    "                    # Calcul de la fonction de perte\n",
    "                    loss =  criterion(y_pred*100, y_batch.to(torch.float32)*100) #torch.mean(torch.abs(y_pred- y_batch.to(torch.float32)))#\n",
    "                    # Backpropagation : calculer le gradient de la loss en fonction de chaque couche\n",
    "                    loss.backward()\n",
    "                    # Clipper le gradient entre 0 et 1 pour plus de stabilité\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    # Descente de gradient : actualisation des paramètres\n",
    "                    optimizer.step()\n",
    "                    loss_total += loss.item()\n",
    "                    # Mise à jour des bars de progression pour suivre l'avancement de l'epoch\n",
    "                    pbar_batch.update(train_batch_size)\n",
    "                    pbar_epoch.update(1)\n",
    "\n",
    "    #Affiche la perte moyenne d'entrainement  Training loss\n",
    "    print(f\"Epoch : {epoch+1}/{epochs} -- Training loss {loss_total/len(train_loader)}\")\n",
    "    #retourne la fonction de perte a la fin de l'entrainement\n",
    "    return criterion\n",
    "\n",
    "def predict(dataloader_val, criterion):\n",
    "    \"\"\"\n",
    "    Évalue le modèle sur les données de validation et calcule la perte moyenne.\n",
    "\n",
    "    Paramètres :\n",
    "    dataloader_val (torch.utils.data.DataLoader) : Le DataLoader contenant les données de validation.\n",
    "    criterion (torch.nn.Module) : La fonction de perte utilisée pour évaluer le modèle.\n",
    "\n",
    "    Retourne :\n",
    "    tuple : Un tuple contenant la perte moyenne, les prédictions et les vraies valeurs.\n",
    "    \"\"\"\n",
    "    # Passer le modèle en évaluation\n",
    "    model.eval()\n",
    "    # Calculer la loss totale\n",
    "    loss_val_total = 0\n",
    "    # Stocker les prédictions et les vraies valeurs.\n",
    "    predictions, true_vals = [], []\n",
    "    for batch in dataloader_val:\n",
    "        X_batch, y_batch = batch\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            # Prédiction du modèle pour un batch donné\n",
    "            y_pred = model(X_batch.to(torch.float32))\n",
    "        # Calcul de la fonction de perte pour l'utiliser comme une métrique\n",
    "        loss = criterion(y_pred, y_batch.to(torch.float32))\n",
    "        # Cumuler la fonction de perte de tous les lots de données.\n",
    "        loss_val_total += loss.item()\n",
    "        # Enregistrer les prédictions pour les utiliser plus tard\n",
    "        predictions.extend(y_pred.detach().cpu().numpy())\n",
    "        # Enregistrer les vraies valeurs pour les utiliser plus tard\n",
    "        true_vals.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # Loss du jeu de données val\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    # Ensemble des prédictions du jeu de données\n",
    "    predictions = np.array(predictions)\n",
    "    # Ensemble des vraies valeurs du jeu de données\n",
    "    true_vals = np.array(true_vals)\n",
    "    \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "# Les résultats de chaque itération sont stockés dans la liste results et sauvegardés dans un fichier CSV.\n",
    "results = []\n",
    "# Crée un objet KFold pour réaliser une validation croisée en 5 plis avec les données mélangées.\n",
    "crossval = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for index, name in enumerate(cols_cible_type):\n",
    "    #Chargement et préparation des données pour chaque type de cible\n",
    "    df = load_df(name)\n",
    "\n",
    "    for year_floor in range(14, 15):  # >= 2022\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        print(\"year\", 2024 - 16 + year_floor)\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        #df_limited : les données sont limitées à une certaine année\n",
    "        df_limited = df[df.CalYear >= year_floor]\n",
    "        #definir la variable cible\n",
    "        X = Create_X(df_limited, index).values\n",
    "\n",
    "        for index_cible, col_cible in enumerate(cols_cible[index]):\n",
    "            if not (col_cible in cols_cible_filter):\n",
    "                continue\n",
    "            print(\n",
    "                \"--------------------------------------------------------------------------------\"\n",
    "            )\n",
    "            print(\"///////////////////////////\", \"cible\", col_cible)\n",
    "            # Pour chaque cible, les étiquettes (y) sont extraites \n",
    "            # et les données sont divisées en ensembles d'entraînement et de test avec train_test_split.\n",
    "            y = df_limited[col_cible].values\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "\n",
    "            # Transforme train et test pour Pytorch\n",
    "            train_set = CustomDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "            test_set = CustomDataset(X_test, y_test)\n",
    "            test_loader = DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "            print(next(iter(train_loader)))\n",
    "            print(next(iter(test_loader)))\n",
    "            # Crée le modèle\n",
    "            model = get_model()\n",
    "            # Entraine le model\n",
    "            criterion = train_model(model, train_loader)\n",
    "            # évalue le modèle\n",
    "            loss, y_train_pred, y_train_true = predict(train_loader, criterion)\n",
    "            loss, y_pred, y_true = predict(test_loader, criterion)\n",
    "            print(f\"Loss: {loss}\")\n",
    "            #Calcul des metriques RMSE\n",
    "            rmse_train = root_mean_squared_error(y_train_true, y_train_pred)\n",
    "            print(f\"RMSE train : {rmse_train}\")\n",
    "            rmse_test = root_mean_squared_error(y_true, y_pred)\n",
    "            print(f\"RMSE test : {rmse_test}\")\n",
    "            # Calcul des metriques MAE\n",
    "            mae_train = mean_absolute_error(y_train_true, y_train_pred)\n",
    "            print(f\"MAE train : {mae_train}\")\n",
    "            mae_test = mean_absolute_error(y_true, y_pred)\n",
    "            print(f\"MAE test : {mae_test}\")\n",
    "            # Ajouter au tableau des résultats\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Target\": col_cible,\n",
    "                    \"Year floor\": 2024 - 16 + year_floor,\n",
    "                    \"Loss\": loss,\n",
    "                    \"RMSE train\": rmse_train,\n",
    "                    \"RMSE test\": rmse_test,\n",
    "                    \"MAE train\": mae_train,\n",
    "                    \"MAE test\": mae_test,\n",
    "                }\n",
    "            )\n",
    "            #Les résultats de chaque itération sont stockés dans la liste results .\n",
    "            df_results = pd.DataFrame(results)\n",
    "            df_results = df_results.sort_values(\n",
    "                by=[\"Target\", \"MAE test\"], ascending=[False, True]\n",
    "            )\n",
    "            #Sauvegarde dans un fichier CSV.\n",
    "            df_results.to_csv(\n",
    "                f\"../data/_Pytorch regression.csv\", sep=\";\", index=False\n",
    "            )\n",
    "\n",
    "print(results)\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by=[\"Target\", \"MAE test\"], ascending=[False, True])\n",
    "df_results.to_csv(f\"../data/_Pytorch regression.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-IA-312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
